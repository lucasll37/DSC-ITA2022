{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Challenge @ ITA 2022</font>\n",
    "# <font color='blue'>Equipe DIOMGIS</font>\n",
    "\n",
    "## <font color='blue'>Fase 1</font>\n",
    "\n",
    "### <font color='blue'>TEMA DO DESAFIO</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](..\\data\\image\\logo.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark\n",
    "\n",
    "# Instala o pacote tensorboard-plugin-profile. \n",
    "# Esse pacote é usado para incrementar funcioalidades no Tensorboard.\n",
    "#!pip install -U tensorboard-plugin-profile\n",
    "\n",
    "# Instala pacote threadpoolctl\n",
    "# Este pacote é uma dependência do pacote SMOTE\n",
    "# !pip install threadpoolctl==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas e Frameworks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, LambdaCallback, TerminateOnNaN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.regularizers import L1L2\n",
    "from tensorboard import notebook\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Equipe DIOMGIS\n",
      "\n",
      "tensorboard: 2.10.0\n",
      "seaborn    : 0.11.2\n",
      "pandas     : 1.4.2\n",
      "matplotlib : 3.5.1\n",
      "numpy      : 1.22.3\n",
      "keras      : 2.10.0\n",
      "tensorflow : 2.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Equipe DIOMGIS\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 2\n",
    "seed = 25\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Confirma se o TensorFlow pode acessar a GPU\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "    raise SystemError('GPU device not found')\n",
    "    \n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 13 00:27:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:65:00.0  On |                  N/A |\n",
      "| 40%   29C    P2    27W / 220W |   1104MiB /  8192MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       732    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      1132    C+G   ...370.37\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      1804    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      2592    C+G   ...txyewy\\MiniSearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3516    C+G   ...o Webcam\\GoPro Webcam.exe    N/A      |\n",
      "|    0   N/A  N/A      6380    C+G   ...\\app-1.0.9006\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A      6892    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      7460    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A      7524    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     10820    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     12216    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13784    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14424    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14448    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15244    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     16708    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A     16788    C+G   ...in7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     17300    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     18096    C+G   ...370.37\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     20628    C+G   ...obeNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     21560    C+G   ...persky VPN 5.7\\ksdeui.exe    N/A      |\n",
      "|    0   N/A  N/A     22696      C   ...ucas\\anaconda3\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     22724    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     22980    C+G   ...x64__pc75e8sa7ep4e\\XD.exe    N/A      |\n",
      "|    0   N/A  N/A     27404    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Estado da GPU\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dados\n",
    "import pickle\n",
    "\n",
    "with open('data/census.pkl', 'rb') as f:\n",
    "    [x_treino, y_treino, x_teste, y_teste] = pickle.load(f)\n",
    "    \n",
    "sns.countplot(y_treino);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Balanceamento de classes\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 'auto',\n",
    "           random_state = None,\n",
    "           k_neighbors = 5,\n",
    "           n_jobs = None)\n",
    "\n",
    "x_treino, y_treino = sm.fit_resample(x_treino, y_treino)\n",
    "\n",
    "sns.countplot(y_treino);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros fixos de treinamento\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "nKFold = 5\n",
    "nPCA = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "reduceDim = PCA(n_components = nPCA,\n",
    "                # copy = True,\n",
    "                # whiten = False,\n",
    "                # svd_solver = 'auto',\n",
    "                # tol = 0.0,\n",
    "                # iterated_power = 'auto',\n",
    "                # n_oversamples = 10,\n",
    "                # power_iteration_normalizer = 'auto',\n",
    "                # random_state = None\n",
    "               )\n",
    "\n",
    "reduceDim.fit(x_treino)\n",
    "\n",
    "x_treino = reduceDim.transform(x_treino)\n",
    "x_teste = reduceDim.transform(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_treino = le.fit_transform(y_treino)\n",
    "y_teste = le.transform(y_teste)\n",
    "\n",
    "y_treino = to_categorical(y_treino, num_classes = 2, dtype='float32')\n",
    "y_teste = to_categorical(y_teste, num_classes = 2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlogdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\\nfile_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\\nfile_writer.set_as_default()\\n\\ndef TBloss(epoch):\\n    tf.summary.scalar(\\'logs\\', data = 8, step=epoch)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "def TBloss(epoch):\n",
    "    tf.summary.scalar('logs', data = 8, step=epoch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs_class/{}\".format(time()))\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose = verbose,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              mode=\"min\",\n",
    "                              verbose = verbose,\n",
    "                              min_delta=0.00001,\n",
    "                              min_lr=0)\n",
    "\n",
    "lambdaCB = LambdaCallback(on_epoch_begin=None,\n",
    "                          on_epoch_end=None,\n",
    "                          on_batch_begin=None,\n",
    "                          on_batch_end=None,\n",
    "                          on_train_begin=None,\n",
    "                          on_train_end=None)\n",
    "\n",
    "callbacks = [tensorboard, earlystop, reduce_lr, lambdaCB, TerminateOnNaN()] # checkpoint,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer,\n",
    "                 layers,\n",
    "                 n_dense,\n",
    "                 activationA,\n",
    "                 activationB,\n",
    "                 regL1,\n",
    "                 regL2,\n",
    "                 dropout):\n",
    "    \n",
    "    stdInitializer = GlorotUniform(seed)\n",
    "    regularizer = L1L2(l1 = regL1, l2 = regL2)\n",
    "    \n",
    "    activations = [activationA, activationB]\n",
    "    currentActivation = 1\n",
    "    \n",
    "    #----Alternar entre as funções de ativação-----\n",
    "    func = activations[currentActivation]\n",
    "    currentActivation = 1 - currentActivation\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_dense,\n",
    "                    kernel_initializer = stdInitializer,\n",
    "                    kernel_regularizer = regularizer,\n",
    "                    bias_regularizer = regularizer,\n",
    "                    activation = func,\n",
    "                    input_shape = (nPCA,)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    for layer in range(layers):\n",
    "        \n",
    "        #----Alternar entre as funções de ativação-----\n",
    "        func = activations[currentActivation]\n",
    "        currentActivation = 1 - currentActivation\n",
    "        #----------------------------------------------\n",
    "        \n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(n_dense,\n",
    "                        kernel_initializer = stdInitializer,\n",
    "                        kernel_regularizer = regularizer,\n",
    "                        bias_regularizer = regularizer,\n",
    "                        activation = func))\n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    \n",
    "    model.add(Dense(2,\n",
    "                    kernel_initializer = stdInitializer,\n",
    "                    kernel_regularizer = regularizer,\n",
    "                    bias_regularizer = regularizer,\n",
    "                    activation = 'softmax'))\n",
    "\n",
    "    \n",
    "    #--------------Loss Function--------------------------\n",
    "    # Lbc = keras.losses.BinaryCrossentropy()\n",
    "    Lcc = keras.losses.CategoricalCrossentropy()\n",
    "    # Lscc = keras.losses.SparseCategoricalCrossentropy()\n",
    "    #-----------------------------------------------------\n",
    "    \n",
    "    #--------------Metric Function------------------------\n",
    "    Mauc = keras.metrics.AUC()\n",
    "    #-----------------------------------------------------\n",
    "    \n",
    "    model.compile(loss = Lcc,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics = [Mauc, \"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,\n",
    "                        verbose = verbose,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "\n",
    "steps = [(\"model\", model)]\n",
    "\n",
    "estimator = Pipeline(steps, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos parametros (GridSearch)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.001\n",
    "\n",
    "opt_SGD = SGD(\n",
    "    learning_rate = learning_rate,\n",
    "    momentum = 0.0,\n",
    "    nesterov = False)\n",
    "\n",
    "opt_RMSprop = RMSprop(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.9,\n",
    "    momentum = 0.0,\n",
    "    epsilon = 1e-07,\n",
    "    centered = False)\n",
    "\n",
    "opt_Adam = Adam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07,\n",
    "    amsgrad = False)\n",
    "\n",
    "opt_Adadelta = Adadelta(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.95,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adagrad = Adagrad(\n",
    "    learning_rate = learning_rate,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adamax = Adamax(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Nadam = Nadam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Ftrl = Ftrl(\n",
    "    learning_rate = learning_rate,\n",
    "    learning_rate_power = -0.5,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    l1_regularization_strength = 0.0,\n",
    "    l2_regularization_strength = 0.0,\n",
    "    l2_shrinkage_regularization_strength = 0.0,\n",
    "    beta = 0.0)\n",
    "\n",
    "params_grid = {\n",
    "    \n",
    "    # optimizer [opt_SGD, opt_RMSprop, opt_Adam, opt_Adadelta, opt_Adagrad, opt_Adamax, opt_Nadam, opt_Ftrl]\n",
    "    'model__optimizer': [opt_Adam],\n",
    "    \n",
    "    # Número de camadas\n",
    "    'model__layers': [4, 5],\n",
    "    \n",
    "    # Neuronios por camada\n",
    "    'model__n_dense': [32],\n",
    "    \n",
    "    # activation ['relu', 'sigmoid', 'tanh', 'selu', 'elu']\n",
    "    'model__activationA': ['sigmoid'],\n",
    "    'model__activationB': ['elu'],\n",
    "    \n",
    "    # Ridge regularizer\n",
    "    'model__regL1': [0],\n",
    "    \n",
    "    # Lasso regularizer\n",
    "    'model__regL2': [0],\n",
    "    \n",
    "    # Dropout regularizer\n",
    "    'model__dropout': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search e Cross Validation\n",
    "'''\n",
    "my_roc_oac_score = make_scorer(score_func = roc_auc_score,\n",
    "                             greater_is_better = True,\n",
    "                             needs_proba = True,\n",
    "                             needs_threshold = False,\n",
    "                             average = 'macro',\n",
    "                             sample_weight = None,\n",
    "                             max_fpr = None,\n",
    "                             multi_class = 'raise',\n",
    "                             labels = None)\n",
    "'''\n",
    "\n",
    "grid = GridSearchCV(estimator = estimator,\n",
    "                    # scoring = 'accuracy',\n",
    "                    verbose = verbose,\n",
    "                    return_train_score = False,\n",
    "                    cv = nKFold,\n",
    "                    # n_jobs = -2 # \"-2\": mantem 1 processador livre\n",
    "                    # pre_dispatch = '2*n_jobs',\n",
    "                    refit = True,\n",
    "                    param_grid = params_grid)\n",
    "\n",
    "# Apesar de y ser multilabel, deve ser passada sem OneRotEncoder\n",
    "# https://github.com/keras-team/keras/issues/9331\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                                        &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E38002D190&gt;)],\n",
       "                                verbose=2),\n",
       "             param_grid={&#x27;model__activationA&#x27;: [&#x27;sigmoid&#x27;],\n",
       "                         &#x27;model__activationB&#x27;: [&#x27;elu&#x27;], &#x27;model__dropout&#x27;: [0],\n",
       "                         &#x27;model__layers&#x27;: [4, 5], &#x27;model__n_dense&#x27;: [32],\n",
       "                         &#x27;model__optimizer&#x27;: [&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760&gt;],\n",
       "                         &#x27;model__regL1&#x27;: [0], &#x27;model__regL2&#x27;: [0]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                                        &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E38002D190&gt;)],\n",
       "                                verbose=2),\n",
       "             param_grid={&#x27;model__activationA&#x27;: [&#x27;sigmoid&#x27;],\n",
       "                         &#x27;model__activationB&#x27;: [&#x27;elu&#x27;], &#x27;model__dropout&#x27;: [0],\n",
       "                         &#x27;model__layers&#x27;: [4, 5], &#x27;model__n_dense&#x27;: [32],\n",
       "                         &#x27;model__optimizer&#x27;: [&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760&gt;],\n",
       "                         &#x27;model__regL1&#x27;: [0], &#x27;model__regL2&#x27;: [0]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E38002D190&gt;)],\n",
       "         verbose=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E38002D190&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('model',\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E38002D190>)],\n",
       "                                verbose=2),\n",
       "             param_grid={'model__activationA': ['sigmoid'],\n",
       "                         'model__activationB': ['elu'], 'model__dropout': [0],\n",
       "                         'model__layers': [4, 5], 'model__n_dense': [32],\n",
       "                         'model__optimizer': [<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>],\n",
       "                         'model__regL1': [0], 'model__regL2': [0]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View grid\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir logs_class (started 3:50:25 ago; port 6006, pid 4708).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7ae2989ee6f6cc65\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7ae2989ee6f6cc65\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monitoramento de Otimização\n",
    "\n",
    "# %tensorboard --logdir=logs/\n",
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/200\n",
      "263/263 - 4s - loss: 0.4792 - auc: 0.8494 - accuracy: 0.7645 - val_loss: 0.4488 - val_auc: 0.8806 - val_accuracy: 0.7783 - lr: 0.0010 - 4s/epoch - 16ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 1s - loss: 0.3706 - auc: 0.9151 - accuracy: 0.8359 - val_loss: 0.4277 - val_auc: 0.8898 - val_accuracy: 0.7910 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 1s - loss: 0.3608 - auc: 0.9193 - accuracy: 0.8398 - val_loss: 0.4538 - val_auc: 0.8766 - val_accuracy: 0.7662 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 1s - loss: 0.3517 - auc: 0.9233 - accuracy: 0.8448 - val_loss: 0.4580 - val_auc: 0.8753 - val_accuracy: 0.7699 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 2s - loss: 0.3448 - auc: 0.9263 - accuracy: 0.8465 - val_loss: 0.4059 - val_auc: 0.8999 - val_accuracy: 0.8010 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3376 - auc: 0.9293 - accuracy: 0.8517 - val_loss: 0.4158 - val_auc: 0.8948 - val_accuracy: 0.7945 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 1s - loss: 0.3329 - auc: 0.9313 - accuracy: 0.8544 - val_loss: 0.4216 - val_auc: 0.8954 - val_accuracy: 0.7928 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3290 - auc: 0.9330 - accuracy: 0.8567 - val_loss: 0.4355 - val_auc: 0.8906 - val_accuracy: 0.7842 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 2s - loss: 0.3252 - auc: 0.9346 - accuracy: 0.8571 - val_loss: 0.4065 - val_auc: 0.8996 - val_accuracy: 0.7971 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 1s - loss: 0.3207 - auc: 0.9365 - accuracy: 0.8597 - val_loss: 0.4239 - val_auc: 0.8940 - val_accuracy: 0.7912 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 1s - loss: 0.3189 - auc: 0.9372 - accuracy: 0.8613 - val_loss: 0.3902 - val_auc: 0.9071 - val_accuracy: 0.8066 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 1s - loss: 0.3156 - auc: 0.9385 - accuracy: 0.8638 - val_loss: 0.4422 - val_auc: 0.8915 - val_accuracy: 0.7863 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 1s - loss: 0.3145 - auc: 0.9389 - accuracy: 0.8632 - val_loss: 0.3999 - val_auc: 0.9044 - val_accuracy: 0.8014 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3117 - auc: 0.9400 - accuracy: 0.8663 - val_loss: 0.4204 - val_auc: 0.8971 - val_accuracy: 0.7916 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 1s - loss: 0.3104 - auc: 0.9405 - accuracy: 0.8676 - val_loss: 0.4208 - val_auc: 0.8988 - val_accuracy: 0.7924 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 1s - loss: 0.3074 - auc: 0.9417 - accuracy: 0.8692 - val_loss: 0.4195 - val_auc: 0.8986 - val_accuracy: 0.7955 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 1s - loss: 0.3043 - auc: 0.9428 - accuracy: 0.8711 - val_loss: 0.4515 - val_auc: 0.8882 - val_accuracy: 0.7781 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 1s - loss: 0.3032 - auc: 0.9433 - accuracy: 0.8700 - val_loss: 0.4200 - val_auc: 0.9027 - val_accuracy: 0.8006 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 1s - loss: 0.3002 - auc: 0.9444 - accuracy: 0.8727 - val_loss: 0.4161 - val_auc: 0.8998 - val_accuracy: 0.7961 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 1s - loss: 0.2990 - auc: 0.9448 - accuracy: 0.8739 - val_loss: 0.4033 - val_auc: 0.9062 - val_accuracy: 0.8059 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 1s - loss: 0.2961 - auc: 0.9459 - accuracy: 0.8754 - val_loss: 0.4019 - val_auc: 0.9070 - val_accuracy: 0.8053 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 1s - loss: 0.2948 - auc: 0.9464 - accuracy: 0.8746 - val_loss: 0.4376 - val_auc: 0.8988 - val_accuracy: 0.7967 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 1s - loss: 0.2929 - auc: 0.9471 - accuracy: 0.8755 - val_loss: 0.4230 - val_auc: 0.9052 - val_accuracy: 0.8006 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 1s - loss: 0.2912 - auc: 0.9477 - accuracy: 0.8775 - val_loss: 0.4249 - val_auc: 0.9007 - val_accuracy: 0.8000 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 1s - loss: 0.2901 - auc: 0.9481 - accuracy: 0.8771 - val_loss: 0.4341 - val_auc: 0.8999 - val_accuracy: 0.7947 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 1s - loss: 0.2885 - auc: 0.9487 - accuracy: 0.8769 - val_loss: 0.4507 - val_auc: 0.8917 - val_accuracy: 0.7795 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 27/200\n",
      "263/263 - 1s - loss: 0.2857 - auc: 0.9497 - accuracy: 0.8780 - val_loss: 0.4265 - val_auc: 0.8984 - val_accuracy: 0.7955 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 28/200\n",
      "263/263 - 1s - loss: 0.2841 - auc: 0.9503 - accuracy: 0.8802 - val_loss: 0.4140 - val_auc: 0.9113 - val_accuracy: 0.8117 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "263/263 - 1s - loss: 0.2830 - auc: 0.9506 - accuracy: 0.8807 - val_loss: 0.4395 - val_auc: 0.8992 - val_accuracy: 0.7953 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 30/200\n",
      "263/263 - 1s - loss: 0.2806 - auc: 0.9515 - accuracy: 0.8813 - val_loss: 0.4493 - val_auc: 0.8993 - val_accuracy: 0.7953 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 31/200\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "263/263 - 1s - loss: 0.2791 - auc: 0.9520 - accuracy: 0.8810 - val_loss: 0.4109 - val_auc: 0.9121 - val_accuracy: 0.8170 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 31: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  48.4s\n",
      "263/263 - 1s - loss: 0.3682 - auc: 0.9164 - accuracy: 0.8126 - 1s/epoch - 4ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=4, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  49.6s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4757 - auc_1: 0.8516 - accuracy: 0.7666 - val_loss: 0.4353 - val_auc_1: 0.8842 - val_accuracy: 0.7857 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 1s - loss: 0.3676 - auc_1: 0.9165 - accuracy: 0.8372 - val_loss: 0.4501 - val_auc_1: 0.8821 - val_accuracy: 0.7828 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 1s - loss: 0.3570 - auc_1: 0.9212 - accuracy: 0.8408 - val_loss: 0.5150 - val_auc_1: 0.8619 - val_accuracy: 0.7535 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 1s - loss: 0.3522 - auc_1: 0.9232 - accuracy: 0.8431 - val_loss: 0.4115 - val_auc_1: 0.8948 - val_accuracy: 0.7973 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 1s - loss: 0.3439 - auc_1: 0.9267 - accuracy: 0.8496 - val_loss: 0.3722 - val_auc_1: 0.9125 - val_accuracy: 0.8182 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 1s - loss: 0.3365 - auc_1: 0.9299 - accuracy: 0.8499 - val_loss: 0.4398 - val_auc_1: 0.8844 - val_accuracy: 0.7816 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 1s - loss: 0.3320 - auc_1: 0.9318 - accuracy: 0.8526 - val_loss: 0.4027 - val_auc_1: 0.9024 - val_accuracy: 0.8057 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 1s - loss: 0.3269 - auc_1: 0.9339 - accuracy: 0.8564 - val_loss: 0.3884 - val_auc_1: 0.9063 - val_accuracy: 0.8096 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 1s - loss: 0.3242 - auc_1: 0.9351 - accuracy: 0.8570 - val_loss: 0.4154 - val_auc_1: 0.8979 - val_accuracy: 0.8014 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 1s - loss: 0.3201 - auc_1: 0.9367 - accuracy: 0.8598 - val_loss: 0.3809 - val_auc_1: 0.9103 - val_accuracy: 0.8158 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 1s - loss: 0.3185 - auc_1: 0.9373 - accuracy: 0.8612 - val_loss: 0.3715 - val_auc_1: 0.9143 - val_accuracy: 0.8180 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 1s - loss: 0.3158 - auc_1: 0.9384 - accuracy: 0.8632 - val_loss: 0.4003 - val_auc_1: 0.9029 - val_accuracy: 0.8051 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 1s - loss: 0.3117 - auc_1: 0.9400 - accuracy: 0.8636 - val_loss: 0.4193 - val_auc_1: 0.8996 - val_accuracy: 0.7971 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 1s - loss: 0.3102 - auc_1: 0.9406 - accuracy: 0.8649 - val_loss: 0.4012 - val_auc_1: 0.9060 - val_accuracy: 0.8047 - lr: 0.0010 - 1s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3076 - auc_1: 0.9416 - accuracy: 0.8670 - val_loss: 0.4557 - val_auc_1: 0.8847 - val_accuracy: 0.7840 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 1s - loss: 0.3053 - auc_1: 0.9425 - accuracy: 0.8683 - val_loss: 0.3809 - val_auc_1: 0.9142 - val_accuracy: 0.8158 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 1s - loss: 0.3032 - auc_1: 0.9433 - accuracy: 0.8688 - val_loss: 0.4795 - val_auc_1: 0.8832 - val_accuracy: 0.7789 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 1s - loss: 0.3024 - auc_1: 0.9436 - accuracy: 0.8677 - val_loss: 0.4248 - val_auc_1: 0.8985 - val_accuracy: 0.7977 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 1s - loss: 0.2994 - auc_1: 0.9447 - accuracy: 0.8696 - val_loss: 0.4402 - val_auc_1: 0.8948 - val_accuracy: 0.7939 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 1s - loss: 0.2969 - auc_1: 0.9456 - accuracy: 0.8713 - val_loss: 0.4008 - val_auc_1: 0.9066 - val_accuracy: 0.8078 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 1s - loss: 0.2942 - auc_1: 0.9467 - accuracy: 0.8729 - val_loss: 0.3956 - val_auc_1: 0.9099 - val_accuracy: 0.8137 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 1s - loss: 0.2933 - auc_1: 0.9470 - accuracy: 0.8720 - val_loss: 0.4070 - val_auc_1: 0.9054 - val_accuracy: 0.8068 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 1s - loss: 0.2910 - auc_1: 0.9479 - accuracy: 0.8746 - val_loss: 0.3961 - val_auc_1: 0.9132 - val_accuracy: 0.8172 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 1s - loss: 0.2890 - auc_1: 0.9485 - accuracy: 0.8752 - val_loss: 0.4391 - val_auc_1: 0.8960 - val_accuracy: 0.7914 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 1s - loss: 0.2865 - auc_1: 0.9494 - accuracy: 0.8766 - val_loss: 0.4248 - val_auc_1: 0.9008 - val_accuracy: 0.8006 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 1s - loss: 0.2839 - auc_1: 0.9504 - accuracy: 0.8785 - val_loss: 0.4498 - val_auc_1: 0.8970 - val_accuracy: 0.7932 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "263/263 - 1s - loss: 0.2829 - auc_1: 0.9507 - accuracy: 0.8781 - val_loss: 0.4081 - val_auc_1: 0.9118 - val_accuracy: 0.8147 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "263/263 - 1s - loss: 0.2810 - auc_1: 0.9514 - accuracy: 0.8805 - val_loss: 0.4312 - val_auc_1: 0.8963 - val_accuracy: 0.7932 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "263/263 - 2s - loss: 0.2793 - auc_1: 0.9520 - accuracy: 0.8805 - val_loss: 0.4285 - val_auc_1: 0.9052 - val_accuracy: 0.8039 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "263/263 - 1s - loss: 0.2776 - auc_1: 0.9526 - accuracy: 0.8795 - val_loss: 0.4671 - val_auc_1: 0.8902 - val_accuracy: 0.7851 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 31/200\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "263/263 - 2s - loss: 0.2749 - auc_1: 0.9536 - accuracy: 0.8829 - val_loss: 0.4667 - val_auc_1: 0.8939 - val_accuracy: 0.7892 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 31: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  46.7s\n",
      "263/263 - 1s - loss: 0.3550 - auc_1: 0.9206 - accuracy: 0.8255 - 1s/epoch - 4ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=4, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  47.8s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4743 - auc_2: 0.8527 - accuracy: 0.7717 - val_loss: 0.4351 - val_auc_2: 0.8864 - val_accuracy: 0.7902 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 1s - loss: 0.3640 - auc_2: 0.9183 - accuracy: 0.8403 - val_loss: 0.4624 - val_auc_2: 0.8729 - val_accuracy: 0.7693 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 1s - loss: 0.3541 - auc_2: 0.9225 - accuracy: 0.8434 - val_loss: 0.4147 - val_auc_2: 0.8961 - val_accuracy: 0.7963 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 1s - loss: 0.3459 - auc_2: 0.9260 - accuracy: 0.8453 - val_loss: 0.4267 - val_auc_2: 0.8918 - val_accuracy: 0.7908 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 1s - loss: 0.3381 - auc_2: 0.9292 - accuracy: 0.8503 - val_loss: 0.4318 - val_auc_2: 0.8896 - val_accuracy: 0.7896 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 1s - loss: 0.3327 - auc_2: 0.9315 - accuracy: 0.8528 - val_loss: 0.4363 - val_auc_2: 0.8898 - val_accuracy: 0.7846 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 1s - loss: 0.3269 - auc_2: 0.9339 - accuracy: 0.8573 - val_loss: 0.3839 - val_auc_2: 0.9090 - val_accuracy: 0.8133 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 1s - loss: 0.3217 - auc_2: 0.9361 - accuracy: 0.8595 - val_loss: 0.3963 - val_auc_2: 0.9060 - val_accuracy: 0.8092 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 1s - loss: 0.3177 - auc_2: 0.9377 - accuracy: 0.8612 - val_loss: 0.3971 - val_auc_2: 0.9063 - val_accuracy: 0.8074 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3144 - auc_2: 0.9390 - accuracy: 0.8643 - val_loss: 0.4719 - val_auc_2: 0.8782 - val_accuracy: 0.7740 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3119 - auc_2: 0.9400 - accuracy: 0.8646 - val_loss: 0.3764 - val_auc_2: 0.9160 - val_accuracy: 0.8182 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3106 - auc_2: 0.9405 - accuracy: 0.8662 - val_loss: 0.4290 - val_auc_2: 0.8946 - val_accuracy: 0.7908 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 1s - loss: 0.3081 - auc_2: 0.9415 - accuracy: 0.8655 - val_loss: 0.4392 - val_auc_2: 0.8895 - val_accuracy: 0.7851 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 1s - loss: 0.3057 - auc_2: 0.9424 - accuracy: 0.8692 - val_loss: 0.4172 - val_auc_2: 0.9016 - val_accuracy: 0.7957 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 1s - loss: 0.3033 - auc_2: 0.9433 - accuracy: 0.8691 - val_loss: 0.4356 - val_auc_2: 0.8932 - val_accuracy: 0.7869 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3007 - auc_2: 0.9443 - accuracy: 0.8706 - val_loss: 0.4423 - val_auc_2: 0.8915 - val_accuracy: 0.7883 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 2s - loss: 0.3001 - auc_2: 0.9445 - accuracy: 0.8706 - val_loss: 0.4286 - val_auc_2: 0.8981 - val_accuracy: 0.7922 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 1s - loss: 0.2971 - auc_2: 0.9456 - accuracy: 0.8735 - val_loss: 0.4371 - val_auc_2: 0.8938 - val_accuracy: 0.7857 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 2s - loss: 0.2951 - auc_2: 0.9463 - accuracy: 0.8738 - val_loss: 0.4680 - val_auc_2: 0.8813 - val_accuracy: 0.7738 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.2924 - auc_2: 0.9473 - accuracy: 0.8763 - val_loss: 0.4254 - val_auc_2: 0.9006 - val_accuracy: 0.7924 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.2918 - auc_2: 0.9475 - accuracy: 0.8757 - val_loss: 0.4405 - val_auc_2: 0.8948 - val_accuracy: 0.7887 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 2s - loss: 0.2884 - auc_2: 0.9488 - accuracy: 0.8774 - val_loss: 0.4295 - val_auc_2: 0.8965 - val_accuracy: 0.7920 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 1s - loss: 0.2867 - auc_2: 0.9493 - accuracy: 0.8781 - val_loss: 0.4015 - val_auc_2: 0.9103 - val_accuracy: 0.8106 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 1s - loss: 0.2858 - auc_2: 0.9497 - accuracy: 0.8782 - val_loss: 0.4440 - val_auc_2: 0.8974 - val_accuracy: 0.7928 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 1s - loss: 0.2845 - auc_2: 0.9501 - accuracy: 0.8791 - val_loss: 0.4747 - val_auc_2: 0.8891 - val_accuracy: 0.7799 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 2s - loss: 0.2820 - auc_2: 0.9510 - accuracy: 0.8795 - val_loss: 0.3892 - val_auc_2: 0.9152 - val_accuracy: 0.8209 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "263/263 - 2s - loss: 0.2809 - auc_2: 0.9515 - accuracy: 0.8802 - val_loss: 0.4229 - val_auc_2: 0.9050 - val_accuracy: 0.8033 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "263/263 - 2s - loss: 0.2780 - auc_2: 0.9524 - accuracy: 0.8822 - val_loss: 0.4733 - val_auc_2: 0.8879 - val_accuracy: 0.7830 - lr: 0.0010 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "263/263 - 1s - loss: 0.2769 - auc_2: 0.9528 - accuracy: 0.8820 - val_loss: 0.4779 - val_auc_2: 0.8931 - val_accuracy: 0.7834 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "263/263 - 2s - loss: 0.2759 - auc_2: 0.9532 - accuracy: 0.8838 - val_loss: 0.4387 - val_auc_2: 0.9022 - val_accuracy: 0.7973 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 31/200\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "263/263 - 2s - loss: 0.2738 - auc_2: 0.9539 - accuracy: 0.8843 - val_loss: 0.4556 - val_auc_2: 0.8956 - val_accuracy: 0.7887 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 31: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  48.3s\n",
      "263/263 - 1s - loss: 0.3705 - auc_2: 0.9171 - accuracy: 0.8193 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=4, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  49.5s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4687 - auc_3: 0.8540 - accuracy: 0.7575 - val_loss: 0.3653 - val_auc_3: 0.9160 - val_accuracy: 0.8225 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 1s - loss: 0.3774 - auc_3: 0.9104 - accuracy: 0.8212 - val_loss: 0.4257 - val_auc_3: 0.8884 - val_accuracy: 0.7894 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3673 - auc_3: 0.9150 - accuracy: 0.8269 - val_loss: 0.3857 - val_auc_3: 0.9046 - val_accuracy: 0.8072 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 1s - loss: 0.3623 - auc_3: 0.9171 - accuracy: 0.8274 - val_loss: 0.3926 - val_auc_3: 0.9047 - val_accuracy: 0.8094 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 2s - loss: 0.3549 - auc_3: 0.9206 - accuracy: 0.8333 - val_loss: 0.3778 - val_auc_3: 0.9101 - val_accuracy: 0.8129 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3500 - auc_3: 0.9228 - accuracy: 0.8360 - val_loss: 0.3831 - val_auc_3: 0.9095 - val_accuracy: 0.8151 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 2s - loss: 0.3446 - auc_3: 0.9252 - accuracy: 0.8376 - val_loss: 0.3347 - val_auc_3: 0.9304 - val_accuracy: 0.8401 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3403 - auc_3: 0.9271 - accuracy: 0.8408 - val_loss: 0.3559 - val_auc_3: 0.9196 - val_accuracy: 0.8227 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 1s - loss: 0.3360 - auc_3: 0.9290 - accuracy: 0.8442 - val_loss: 0.3499 - val_auc_3: 0.9218 - val_accuracy: 0.8256 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3339 - auc_3: 0.9298 - accuracy: 0.8431 - val_loss: 0.3820 - val_auc_3: 0.9114 - val_accuracy: 0.8098 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 1s - loss: 0.3307 - auc_3: 0.9314 - accuracy: 0.8482 - val_loss: 0.3840 - val_auc_3: 0.9090 - val_accuracy: 0.8086 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3300 - auc_3: 0.9314 - accuracy: 0.8463 - val_loss: 0.3581 - val_auc_3: 0.9183 - val_accuracy: 0.8184 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 1s - loss: 0.3273 - auc_3: 0.9327 - accuracy: 0.8479 - val_loss: 0.3776 - val_auc_3: 0.9095 - val_accuracy: 0.8090 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3248 - auc_3: 0.9336 - accuracy: 0.8494 - val_loss: 0.3661 - val_auc_3: 0.9152 - val_accuracy: 0.8162 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3221 - auc_3: 0.9348 - accuracy: 0.8502 - val_loss: 0.3565 - val_auc_3: 0.9207 - val_accuracy: 0.8256 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3214 - auc_3: 0.9351 - accuracy: 0.8520 - val_loss: 0.3629 - val_auc_3: 0.9186 - val_accuracy: 0.8168 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 2s - loss: 0.3190 - auc_3: 0.9360 - accuracy: 0.8520 - val_loss: 0.3456 - val_auc_3: 0.9266 - val_accuracy: 0.8315 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 2s - loss: 0.3173 - auc_3: 0.9368 - accuracy: 0.8522 - val_loss: 0.3551 - val_auc_3: 0.9226 - val_accuracy: 0.8276 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 1s - loss: 0.3152 - auc_3: 0.9376 - accuracy: 0.8547 - val_loss: 0.3532 - val_auc_3: 0.9229 - val_accuracy: 0.8264 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.3145 - auc_3: 0.9379 - accuracy: 0.8535 - val_loss: 0.3471 - val_auc_3: 0.9284 - val_accuracy: 0.8377 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.3129 - auc_3: 0.9386 - accuracy: 0.8555 - val_loss: 0.3708 - val_auc_3: 0.9164 - val_accuracy: 0.8184 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 2s - loss: 0.3099 - auc_3: 0.9398 - accuracy: 0.8572 - val_loss: 0.3903 - val_auc_3: 0.9116 - val_accuracy: 0.8147 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 2s - loss: 0.3091 - auc_3: 0.9401 - accuracy: 0.8578 - val_loss: 0.3770 - val_auc_3: 0.9144 - val_accuracy: 0.8156 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 1s - loss: 0.3073 - auc_3: 0.9408 - accuracy: 0.8585 - val_loss: 0.3749 - val_auc_3: 0.9184 - val_accuracy: 0.8223 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 2s - loss: 0.3061 - auc_3: 0.9412 - accuracy: 0.8587 - val_loss: 0.3811 - val_auc_3: 0.9163 - val_accuracy: 0.8168 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 1s - loss: 0.3043 - auc_3: 0.9420 - accuracy: 0.8593 - val_loss: 0.3917 - val_auc_3: 0.9126 - val_accuracy: 0.8149 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "263/263 - 2s - loss: 0.3020 - auc_3: 0.9427 - accuracy: 0.8611 - val_loss: 0.3775 - val_auc_3: 0.9181 - val_accuracy: 0.8242 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 27: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  43.4s\n",
      "263/263 - 1s - loss: 0.4217 - auc_3: 0.8884 - accuracy: 0.8018 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=4, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  44.6s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4540 - auc_4: 0.8639 - accuracy: 0.7733 - val_loss: 0.3644 - val_auc_4: 0.9161 - val_accuracy: 0.8242 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 2s - loss: 0.3715 - auc_4: 0.9127 - accuracy: 0.8219 - val_loss: 0.3498 - val_auc_4: 0.9225 - val_accuracy: 0.8317 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3624 - auc_4: 0.9169 - accuracy: 0.8282 - val_loss: 0.3464 - val_auc_4: 0.9243 - val_accuracy: 0.8354 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 1s - loss: 0.3563 - auc_4: 0.9195 - accuracy: 0.8294 - val_loss: 0.3491 - val_auc_4: 0.9227 - val_accuracy: 0.8319 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 1s - loss: 0.3519 - auc_4: 0.9215 - accuracy: 0.8322 - val_loss: 0.3485 - val_auc_4: 0.9224 - val_accuracy: 0.8280 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3474 - auc_4: 0.9235 - accuracy: 0.8351 - val_loss: 0.3374 - val_auc_4: 0.9281 - val_accuracy: 0.8391 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 1s - loss: 0.3422 - auc_4: 0.9258 - accuracy: 0.8366 - val_loss: 0.3274 - val_auc_4: 0.9325 - val_accuracy: 0.8430 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3381 - auc_4: 0.9277 - accuracy: 0.8401 - val_loss: 0.3280 - val_auc_4: 0.9319 - val_accuracy: 0.8463 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 2s - loss: 0.3357 - auc_4: 0.9288 - accuracy: 0.8422 - val_loss: 0.3360 - val_auc_4: 0.9295 - val_accuracy: 0.8379 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3325 - auc_4: 0.9302 - accuracy: 0.8426 - val_loss: 0.3373 - val_auc_4: 0.9281 - val_accuracy: 0.8346 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3310 - auc_4: 0.9308 - accuracy: 0.8445 - val_loss: 0.3367 - val_auc_4: 0.9286 - val_accuracy: 0.8356 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3287 - auc_4: 0.9318 - accuracy: 0.8448 - val_loss: 0.3421 - val_auc_4: 0.9259 - val_accuracy: 0.8340 - lr: 0.0010 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "263/263 - 2s - loss: 0.3267 - auc_4: 0.9327 - accuracy: 0.8457 - val_loss: 0.3387 - val_auc_4: 0.9273 - val_accuracy: 0.8346 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3255 - auc_4: 0.9332 - accuracy: 0.8461 - val_loss: 0.3402 - val_auc_4: 0.9292 - val_accuracy: 0.8366 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3239 - auc_4: 0.9338 - accuracy: 0.8459 - val_loss: 0.3546 - val_auc_4: 0.9200 - val_accuracy: 0.8248 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 1s - loss: 0.3216 - auc_4: 0.9349 - accuracy: 0.8513 - val_loss: 0.3335 - val_auc_4: 0.9309 - val_accuracy: 0.8422 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 1s - loss: 0.3212 - auc_4: 0.9350 - accuracy: 0.8489 - val_loss: 0.3438 - val_auc_4: 0.9252 - val_accuracy: 0.8309 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 1s - loss: 0.3192 - auc_4: 0.9358 - accuracy: 0.8509 - val_loss: 0.3589 - val_auc_4: 0.9191 - val_accuracy: 0.8227 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 2s - loss: 0.3182 - auc_4: 0.9362 - accuracy: 0.8507 - val_loss: 0.3290 - val_auc_4: 0.9330 - val_accuracy: 0.8422 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.3160 - auc_4: 0.9370 - accuracy: 0.8512 - val_loss: 0.3361 - val_auc_4: 0.9313 - val_accuracy: 0.8428 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 1s - loss: 0.3153 - auc_4: 0.9374 - accuracy: 0.8514 - val_loss: 0.3367 - val_auc_4: 0.9326 - val_accuracy: 0.8432 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 1s - loss: 0.3139 - auc_4: 0.9377 - accuracy: 0.8510 - val_loss: 0.3391 - val_auc_4: 0.9290 - val_accuracy: 0.8391 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 1s - loss: 0.3126 - auc_4: 0.9385 - accuracy: 0.8545 - val_loss: 0.3534 - val_auc_4: 0.9237 - val_accuracy: 0.8303 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 1s - loss: 0.3112 - auc_4: 0.9389 - accuracy: 0.8536 - val_loss: 0.3493 - val_auc_4: 0.9237 - val_accuracy: 0.8321 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 1s - loss: 0.3089 - auc_4: 0.9400 - accuracy: 0.8549 - val_loss: 0.3480 - val_auc_4: 0.9271 - val_accuracy: 0.8395 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 1s - loss: 0.3094 - auc_4: 0.9397 - accuracy: 0.8555 - val_loss: 0.3579 - val_auc_4: 0.9208 - val_accuracy: 0.8244 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "263/263 - 1s - loss: 0.3073 - auc_4: 0.9406 - accuracy: 0.8565 - val_loss: 0.3499 - val_auc_4: 0.9295 - val_accuracy: 0.8391 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 27: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  42.6s\n",
      "263/263 - 1s - loss: 0.5179 - auc_4: 0.8275 - accuracy: 0.7510 - 1s/epoch - 4ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=4, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  43.7s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4875 - auc_5: 0.8440 - accuracy: 0.7534 - val_loss: 0.4185 - val_auc_5: 0.8952 - val_accuracy: 0.7973 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 1s - loss: 0.3758 - auc_5: 0.9134 - accuracy: 0.8375 - val_loss: 0.4491 - val_auc_5: 0.8814 - val_accuracy: 0.7816 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3636 - auc_5: 0.9187 - accuracy: 0.8389 - val_loss: 0.4163 - val_auc_5: 0.8934 - val_accuracy: 0.7965 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 2s - loss: 0.3547 - auc_5: 0.9223 - accuracy: 0.8439 - val_loss: 0.4320 - val_auc_5: 0.8904 - val_accuracy: 0.7896 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 2s - loss: 0.3473 - auc_5: 0.9254 - accuracy: 0.8463 - val_loss: 0.4184 - val_auc_5: 0.8939 - val_accuracy: 0.7894 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3416 - auc_5: 0.9278 - accuracy: 0.8486 - val_loss: 0.4441 - val_auc_5: 0.8840 - val_accuracy: 0.7758 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 1s - loss: 0.3347 - auc_5: 0.9307 - accuracy: 0.8530 - val_loss: 0.4043 - val_auc_5: 0.8970 - val_accuracy: 0.7996 - lr: 0.0010 - 1s/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 1s - loss: 0.3293 - auc_5: 0.9330 - accuracy: 0.8566 - val_loss: 0.4384 - val_auc_5: 0.8883 - val_accuracy: 0.7873 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 1s - loss: 0.3260 - auc_5: 0.9344 - accuracy: 0.8575 - val_loss: 0.4111 - val_auc_5: 0.8958 - val_accuracy: 0.7930 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3224 - auc_5: 0.9359 - accuracy: 0.8593 - val_loss: 0.4098 - val_auc_5: 0.9001 - val_accuracy: 0.7973 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3198 - auc_5: 0.9369 - accuracy: 0.8621 - val_loss: 0.3915 - val_auc_5: 0.9052 - val_accuracy: 0.8043 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 1s - loss: 0.3167 - auc_5: 0.9382 - accuracy: 0.8635 - val_loss: 0.4002 - val_auc_5: 0.9063 - val_accuracy: 0.8027 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 2s - loss: 0.3135 - auc_5: 0.9394 - accuracy: 0.8648 - val_loss: 0.4032 - val_auc_5: 0.9065 - val_accuracy: 0.8063 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3116 - auc_5: 0.9402 - accuracy: 0.8645 - val_loss: 0.3917 - val_auc_5: 0.9051 - val_accuracy: 0.8002 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3095 - auc_5: 0.9410 - accuracy: 0.8659 - val_loss: 0.4291 - val_auc_5: 0.8967 - val_accuracy: 0.7879 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3064 - auc_5: 0.9421 - accuracy: 0.8685 - val_loss: 0.4218 - val_auc_5: 0.8980 - val_accuracy: 0.7894 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 1s - loss: 0.3048 - auc_5: 0.9428 - accuracy: 0.8684 - val_loss: 0.4023 - val_auc_5: 0.9080 - val_accuracy: 0.8045 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 2s - loss: 0.3020 - auc_5: 0.9439 - accuracy: 0.8700 - val_loss: 0.3980 - val_auc_5: 0.9074 - val_accuracy: 0.8000 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 2s - loss: 0.3001 - auc_5: 0.9446 - accuracy: 0.8708 - val_loss: 0.4574 - val_auc_5: 0.8914 - val_accuracy: 0.7801 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.2982 - auc_5: 0.9453 - accuracy: 0.8721 - val_loss: 0.4109 - val_auc_5: 0.9071 - val_accuracy: 0.8035 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.2963 - auc_5: 0.9460 - accuracy: 0.8737 - val_loss: 0.4219 - val_auc_5: 0.9053 - val_accuracy: 0.8020 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 2s - loss: 0.2957 - auc_5: 0.9462 - accuracy: 0.8729 - val_loss: 0.4321 - val_auc_5: 0.9017 - val_accuracy: 0.7947 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 2s - loss: 0.2921 - auc_5: 0.9475 - accuracy: 0.8750 - val_loss: 0.4464 - val_auc_5: 0.8969 - val_accuracy: 0.7851 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 2s - loss: 0.2907 - auc_5: 0.9481 - accuracy: 0.8758 - val_loss: 0.4537 - val_auc_5: 0.8902 - val_accuracy: 0.7783 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 2s - loss: 0.2893 - auc_5: 0.9485 - accuracy: 0.8766 - val_loss: 0.4441 - val_auc_5: 0.8999 - val_accuracy: 0.7941 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 2s - loss: 0.2873 - auc_5: 0.9492 - accuracy: 0.8778 - val_loss: 0.4036 - val_auc_5: 0.9109 - val_accuracy: 0.8063 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "263/263 - 2s - loss: 0.2867 - auc_5: 0.9495 - accuracy: 0.8772 - val_loss: 0.4647 - val_auc_5: 0.8910 - val_accuracy: 0.7801 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "263/263 - 2s - loss: 0.2841 - auc_5: 0.9504 - accuracy: 0.8793 - val_loss: 0.4181 - val_auc_5: 0.9065 - val_accuracy: 0.8012 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 29/200\n",
      "263/263 - 2s - loss: 0.2827 - auc_5: 0.9508 - accuracy: 0.8802 - val_loss: 0.4415 - val_auc_5: 0.8947 - val_accuracy: 0.7844 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "263/263 - 2s - loss: 0.2813 - auc_5: 0.9514 - accuracy: 0.8800 - val_loss: 0.4632 - val_auc_5: 0.8932 - val_accuracy: 0.7842 - lr: 0.0010 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "263/263 - 2s - loss: 0.2786 - auc_5: 0.9523 - accuracy: 0.8813 - val_loss: 0.4462 - val_auc_5: 0.9022 - val_accuracy: 0.7953 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 31: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  51.1s\n",
      "263/263 - 1s - loss: 0.3658 - auc_5: 0.9161 - accuracy: 0.8152 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=5, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  52.3s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4853 - auc_6: 0.8453 - accuracy: 0.7512 - val_loss: 0.4735 - val_auc_6: 0.8730 - val_accuracy: 0.7685 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 2s - loss: 0.3727 - auc_6: 0.9151 - accuracy: 0.8382 - val_loss: 0.4698 - val_auc_6: 0.8755 - val_accuracy: 0.7697 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3598 - auc_6: 0.9203 - accuracy: 0.8429 - val_loss: 0.4600 - val_auc_6: 0.8732 - val_accuracy: 0.7715 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 2s - loss: 0.3518 - auc_6: 0.9237 - accuracy: 0.8438 - val_loss: 0.4079 - val_auc_6: 0.8955 - val_accuracy: 0.7996 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 2s - loss: 0.3428 - auc_6: 0.9275 - accuracy: 0.8483 - val_loss: 0.4076 - val_auc_6: 0.8972 - val_accuracy: 0.7975 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3373 - auc_6: 0.9297 - accuracy: 0.8512 - val_loss: 0.4390 - val_auc_6: 0.8855 - val_accuracy: 0.7797 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 2s - loss: 0.3317 - auc_6: 0.9320 - accuracy: 0.8542 - val_loss: 0.4323 - val_auc_6: 0.8934 - val_accuracy: 0.7932 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3278 - auc_6: 0.9337 - accuracy: 0.8556 - val_loss: 0.4324 - val_auc_6: 0.8911 - val_accuracy: 0.7881 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 2s - loss: 0.3234 - auc_6: 0.9355 - accuracy: 0.8583 - val_loss: 0.4108 - val_auc_6: 0.9001 - val_accuracy: 0.8023 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3193 - auc_6: 0.9372 - accuracy: 0.8609 - val_loss: 0.4115 - val_auc_6: 0.9006 - val_accuracy: 0.7982 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3167 - auc_6: 0.9381 - accuracy: 0.8624 - val_loss: 0.4042 - val_auc_6: 0.9034 - val_accuracy: 0.7984 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3130 - auc_6: 0.9397 - accuracy: 0.8636 - val_loss: 0.3765 - val_auc_6: 0.9153 - val_accuracy: 0.8156 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 2s - loss: 0.3115 - auc_6: 0.9403 - accuracy: 0.8642 - val_loss: 0.4024 - val_auc_6: 0.9021 - val_accuracy: 0.8047 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3089 - auc_6: 0.9412 - accuracy: 0.8662 - val_loss: 0.3825 - val_auc_6: 0.9091 - val_accuracy: 0.8115 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3068 - auc_6: 0.9420 - accuracy: 0.8663 - val_loss: 0.4212 - val_auc_6: 0.8999 - val_accuracy: 0.7955 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3037 - auc_6: 0.9432 - accuracy: 0.8677 - val_loss: 0.3996 - val_auc_6: 0.9066 - val_accuracy: 0.8023 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 2s - loss: 0.3014 - auc_6: 0.9441 - accuracy: 0.8695 - val_loss: 0.4302 - val_auc_6: 0.8925 - val_accuracy: 0.7838 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 2s - loss: 0.3000 - auc_6: 0.9446 - accuracy: 0.8698 - val_loss: 0.4354 - val_auc_6: 0.8912 - val_accuracy: 0.7853 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 2s - loss: 0.2976 - auc_6: 0.9455 - accuracy: 0.8712 - val_loss: 0.4214 - val_auc_6: 0.9029 - val_accuracy: 0.8000 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.2966 - auc_6: 0.9459 - accuracy: 0.8712 - val_loss: 0.4483 - val_auc_6: 0.8943 - val_accuracy: 0.7883 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.2950 - auc_6: 0.9464 - accuracy: 0.8736 - val_loss: 0.4188 - val_auc_6: 0.9049 - val_accuracy: 0.8025 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 2s - loss: 0.2931 - auc_6: 0.9472 - accuracy: 0.8716 - val_loss: 0.4303 - val_auc_6: 0.9041 - val_accuracy: 0.7977 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 2s - loss: 0.2923 - auc_6: 0.9474 - accuracy: 0.8739 - val_loss: 0.4568 - val_auc_6: 0.8866 - val_accuracy: 0.7775 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 2s - loss: 0.2893 - auc_6: 0.9485 - accuracy: 0.8748 - val_loss: 0.4389 - val_auc_6: 0.8975 - val_accuracy: 0.7943 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 2s - loss: 0.2871 - auc_6: 0.9493 - accuracy: 0.8770 - val_loss: 0.4314 - val_auc_6: 0.9030 - val_accuracy: 0.8010 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 2s - loss: 0.2863 - auc_6: 0.9496 - accuracy: 0.8773 - val_loss: 0.4338 - val_auc_6: 0.8979 - val_accuracy: 0.7908 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "263/263 - 2s - loss: 0.2829 - auc_6: 0.9508 - accuracy: 0.8782 - val_loss: 0.4490 - val_auc_6: 0.8983 - val_accuracy: 0.7953 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "263/263 - 2s - loss: 0.2820 - auc_6: 0.9512 - accuracy: 0.8795 - val_loss: 0.4476 - val_auc_6: 0.8968 - val_accuracy: 0.7900 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 29/200\n",
      "263/263 - 2s - loss: 0.2811 - auc_6: 0.9514 - accuracy: 0.8797 - val_loss: 0.4106 - val_auc_6: 0.9123 - val_accuracy: 0.8119 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "263/263 - 2s - loss: 0.2786 - auc_6: 0.9523 - accuracy: 0.8807 - val_loss: 0.4225 - val_auc_6: 0.9075 - val_accuracy: 0.8092 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 31/200\n",
      "263/263 - 1s - loss: 0.2776 - auc_6: 0.9527 - accuracy: 0.8813 - val_loss: 0.4483 - val_auc_6: 0.9022 - val_accuracy: 0.7996 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 32/200\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "263/263 - 2s - loss: 0.2760 - auc_6: 0.9532 - accuracy: 0.8821 - val_loss: 0.4498 - val_auc_6: 0.8975 - val_accuracy: 0.7934 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 32: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  52.6s\n",
      "263/263 - 1s - loss: 0.3585 - auc_6: 0.9216 - accuracy: 0.8255 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=5, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  53.8s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4788 - auc_7: 0.8518 - accuracy: 0.7601 - val_loss: 0.4927 - val_auc_7: 0.8625 - val_accuracy: 0.7570 - lr: 0.0010 - 3s/epoch - 11ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 2s - loss: 0.3688 - auc_7: 0.9170 - accuracy: 0.8387 - val_loss: 0.4275 - val_auc_7: 0.8900 - val_accuracy: 0.7947 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3560 - auc_7: 0.9222 - accuracy: 0.8437 - val_loss: 0.4013 - val_auc_7: 0.9009 - val_accuracy: 0.8063 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 2s - loss: 0.3470 - auc_7: 0.9258 - accuracy: 0.8467 - val_loss: 0.3930 - val_auc_7: 0.9040 - val_accuracy: 0.8117 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 1s - loss: 0.3392 - auc_7: 0.9290 - accuracy: 0.8500 - val_loss: 0.4387 - val_auc_7: 0.8874 - val_accuracy: 0.7881 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3325 - auc_7: 0.9318 - accuracy: 0.8534 - val_loss: 0.3695 - val_auc_7: 0.9164 - val_accuracy: 0.8223 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 2s - loss: 0.3276 - auc_7: 0.9338 - accuracy: 0.8555 - val_loss: 0.3975 - val_auc_7: 0.9053 - val_accuracy: 0.8061 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3223 - auc_7: 0.9360 - accuracy: 0.8590 - val_loss: 0.4222 - val_auc_7: 0.8984 - val_accuracy: 0.7977 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 2s - loss: 0.3174 - auc_7: 0.9380 - accuracy: 0.8619 - val_loss: 0.3950 - val_auc_7: 0.9073 - val_accuracy: 0.8092 - lr: 0.0010 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3159 - auc_7: 0.9385 - accuracy: 0.8623 - val_loss: 0.3993 - val_auc_7: 0.9015 - val_accuracy: 0.7996 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3109 - auc_7: 0.9405 - accuracy: 0.8654 - val_loss: 0.4110 - val_auc_7: 0.9009 - val_accuracy: 0.8010 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3094 - auc_7: 0.9411 - accuracy: 0.8660 - val_loss: 0.4121 - val_auc_7: 0.8977 - val_accuracy: 0.7977 - lr: 0.0010 - 2s/epoch - 8ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 2s - loss: 0.3060 - auc_7: 0.9424 - accuracy: 0.8681 - val_loss: 0.4310 - val_auc_7: 0.8978 - val_accuracy: 0.7916 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3041 - auc_7: 0.9431 - accuracy: 0.8708 - val_loss: 0.4118 - val_auc_7: 0.9026 - val_accuracy: 0.7988 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3028 - auc_7: 0.9436 - accuracy: 0.8704 - val_loss: 0.3863 - val_auc_7: 0.9128 - val_accuracy: 0.8123 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3005 - auc_7: 0.9445 - accuracy: 0.8699 - val_loss: 0.4206 - val_auc_7: 0.9005 - val_accuracy: 0.7973 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 2s - loss: 0.2980 - auc_7: 0.9454 - accuracy: 0.8714 - val_loss: 0.4472 - val_auc_7: 0.8885 - val_accuracy: 0.7826 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 2s - loss: 0.2953 - auc_7: 0.9464 - accuracy: 0.8730 - val_loss: 0.4469 - val_auc_7: 0.8943 - val_accuracy: 0.7898 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 2s - loss: 0.2943 - auc_7: 0.9468 - accuracy: 0.8743 - val_loss: 0.4064 - val_auc_7: 0.9063 - val_accuracy: 0.8051 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.2930 - auc_7: 0.9472 - accuracy: 0.8750 - val_loss: 0.4368 - val_auc_7: 0.8963 - val_accuracy: 0.7926 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.2902 - auc_7: 0.9482 - accuracy: 0.8761 - val_loss: 0.4350 - val_auc_7: 0.9012 - val_accuracy: 0.8006 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 2s - loss: 0.2888 - auc_7: 0.9487 - accuracy: 0.8760 - val_loss: 0.4478 - val_auc_7: 0.8942 - val_accuracy: 0.7859 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 2s - loss: 0.2871 - auc_7: 0.9493 - accuracy: 0.8770 - val_loss: 0.4711 - val_auc_7: 0.8823 - val_accuracy: 0.7750 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 2s - loss: 0.2860 - auc_7: 0.9498 - accuracy: 0.8773 - val_loss: 0.4303 - val_auc_7: 0.9031 - val_accuracy: 0.8010 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 2s - loss: 0.2848 - auc_7: 0.9502 - accuracy: 0.8791 - val_loss: 0.4193 - val_auc_7: 0.9050 - val_accuracy: 0.7986 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "263/263 - 2s - loss: 0.2822 - auc_7: 0.9511 - accuracy: 0.8790 - val_loss: 0.4333 - val_auc_7: 0.9023 - val_accuracy: 0.7982 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  44.0s\n",
      "263/263 - 1s - loss: 0.3689 - auc_7: 0.9158 - accuracy: 0.8176 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=5, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  45.3s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4685 - auc_8: 0.8562 - accuracy: 0.7619 - val_loss: 0.3983 - val_auc_8: 0.9020 - val_accuracy: 0.8045 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 2s - loss: 0.3794 - auc_8: 0.9103 - accuracy: 0.8231 - val_loss: 0.3744 - val_auc_8: 0.9123 - val_accuracy: 0.8141 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3684 - auc_8: 0.9149 - accuracy: 0.8270 - val_loss: 0.3782 - val_auc_8: 0.9104 - val_accuracy: 0.8143 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 2s - loss: 0.3616 - auc_8: 0.9177 - accuracy: 0.8302 - val_loss: 0.3546 - val_auc_8: 0.9196 - val_accuracy: 0.8299 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 2s - loss: 0.3566 - auc_8: 0.9199 - accuracy: 0.8329 - val_loss: 0.3727 - val_auc_8: 0.9133 - val_accuracy: 0.8180 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3508 - auc_8: 0.9224 - accuracy: 0.8348 - val_loss: 0.3731 - val_auc_8: 0.9113 - val_accuracy: 0.8160 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 2s - loss: 0.3461 - auc_8: 0.9245 - accuracy: 0.8369 - val_loss: 0.3366 - val_auc_8: 0.9292 - val_accuracy: 0.8401 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3420 - auc_8: 0.9263 - accuracy: 0.8394 - val_loss: 0.3812 - val_auc_8: 0.9070 - val_accuracy: 0.8113 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 2s - loss: 0.3392 - auc_8: 0.9276 - accuracy: 0.8415 - val_loss: 0.3875 - val_auc_8: 0.9068 - val_accuracy: 0.8096 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3364 - auc_8: 0.9288 - accuracy: 0.8420 - val_loss: 0.3625 - val_auc_8: 0.9194 - val_accuracy: 0.8248 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3337 - auc_8: 0.9300 - accuracy: 0.8441 - val_loss: 0.3832 - val_auc_8: 0.9091 - val_accuracy: 0.8125 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3302 - auc_8: 0.9315 - accuracy: 0.8452 - val_loss: 0.3632 - val_auc_8: 0.9218 - val_accuracy: 0.8256 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 2s - loss: 0.3282 - auc_8: 0.9324 - accuracy: 0.8484 - val_loss: 0.3555 - val_auc_8: 0.9233 - val_accuracy: 0.8307 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3255 - auc_8: 0.9335 - accuracy: 0.8486 - val_loss: 0.3702 - val_auc_8: 0.9160 - val_accuracy: 0.8205 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3232 - auc_8: 0.9344 - accuracy: 0.8509 - val_loss: 0.3754 - val_auc_8: 0.9129 - val_accuracy: 0.8147 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3223 - auc_8: 0.9348 - accuracy: 0.8517 - val_loss: 0.3808 - val_auc_8: 0.9113 - val_accuracy: 0.8158 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 2s - loss: 0.3194 - auc_8: 0.9360 - accuracy: 0.8518 - val_loss: 0.3515 - val_auc_8: 0.9250 - val_accuracy: 0.8315 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 2s - loss: 0.3190 - auc_8: 0.9361 - accuracy: 0.8510 - val_loss: 0.3654 - val_auc_8: 0.9189 - val_accuracy: 0.8229 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 2s - loss: 0.3157 - auc_8: 0.9375 - accuracy: 0.8545 - val_loss: 0.4018 - val_auc_8: 0.9019 - val_accuracy: 0.8010 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 2s - loss: 0.3143 - auc_8: 0.9381 - accuracy: 0.8547 - val_loss: 0.3736 - val_auc_8: 0.9147 - val_accuracy: 0.8235 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.3142 - auc_8: 0.9381 - accuracy: 0.8546 - val_loss: 0.3818 - val_auc_8: 0.9124 - val_accuracy: 0.8166 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 2s - loss: 0.3115 - auc_8: 0.9391 - accuracy: 0.8547 - val_loss: 0.3583 - val_auc_8: 0.9244 - val_accuracy: 0.8319 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 2s - loss: 0.3085 - auc_8: 0.9403 - accuracy: 0.8563 - val_loss: 0.3769 - val_auc_8: 0.9152 - val_accuracy: 0.8217 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 2s - loss: 0.3080 - auc_8: 0.9405 - accuracy: 0.8571 - val_loss: 0.3569 - val_auc_8: 0.9241 - val_accuracy: 0.8330 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 2s - loss: 0.3068 - auc_8: 0.9409 - accuracy: 0.8566 - val_loss: 0.3800 - val_auc_8: 0.9148 - val_accuracy: 0.8211 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "263/263 - 2s - loss: 0.3044 - auc_8: 0.9419 - accuracy: 0.8581 - val_loss: 0.3820 - val_auc_8: 0.9152 - val_accuracy: 0.8180 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 27/200\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "263/263 - 2s - loss: 0.3026 - auc_8: 0.9426 - accuracy: 0.8590 - val_loss: 0.3907 - val_auc_8: 0.9104 - val_accuracy: 0.8129 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 27: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  46.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 - 1s - loss: 0.4135 - auc_8: 0.8932 - accuracy: 0.8078 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=5, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  47.9s\n",
      "Epoch 1/200\n",
      "263/263 - 3s - loss: 0.4595 - auc_9: 0.8610 - accuracy: 0.7682 - val_loss: 0.3539 - val_auc_9: 0.9225 - val_accuracy: 0.8307 - lr: 0.0010 - 3s/epoch - 12ms/step\n",
      "Epoch 2/200\n",
      "263/263 - 2s - loss: 0.3745 - auc_9: 0.9122 - accuracy: 0.8230 - val_loss: 0.3663 - val_auc_9: 0.9154 - val_accuracy: 0.8184 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "263/263 - 2s - loss: 0.3639 - auc_9: 0.9166 - accuracy: 0.8278 - val_loss: 0.3452 - val_auc_9: 0.9247 - val_accuracy: 0.8328 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 4/200\n",
      "263/263 - 2s - loss: 0.3557 - auc_9: 0.9202 - accuracy: 0.8314 - val_loss: 0.3422 - val_auc_9: 0.9258 - val_accuracy: 0.8346 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "263/263 - 2s - loss: 0.3492 - auc_9: 0.9230 - accuracy: 0.8341 - val_loss: 0.3426 - val_auc_9: 0.9251 - val_accuracy: 0.8319 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 6/200\n",
      "263/263 - 2s - loss: 0.3443 - auc_9: 0.9250 - accuracy: 0.8364 - val_loss: 0.3274 - val_auc_9: 0.9328 - val_accuracy: 0.8442 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "263/263 - 1s - loss: 0.3400 - auc_9: 0.9270 - accuracy: 0.8393 - val_loss: 0.3291 - val_auc_9: 0.9319 - val_accuracy: 0.8454 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "263/263 - 2s - loss: 0.3365 - auc_9: 0.9285 - accuracy: 0.8408 - val_loss: 0.3304 - val_auc_9: 0.9315 - val_accuracy: 0.8432 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 9/200\n",
      "263/263 - 2s - loss: 0.3338 - auc_9: 0.9299 - accuracy: 0.8426 - val_loss: 0.3485 - val_auc_9: 0.9229 - val_accuracy: 0.8301 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "263/263 - 2s - loss: 0.3311 - auc_9: 0.9309 - accuracy: 0.8440 - val_loss: 0.3351 - val_auc_9: 0.9291 - val_accuracy: 0.8381 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "263/263 - 2s - loss: 0.3283 - auc_9: 0.9321 - accuracy: 0.8437 - val_loss: 0.3302 - val_auc_9: 0.9322 - val_accuracy: 0.8452 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 12/200\n",
      "263/263 - 2s - loss: 0.3268 - auc_9: 0.9326 - accuracy: 0.8455 - val_loss: 0.3299 - val_auc_9: 0.9318 - val_accuracy: 0.8452 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "263/263 - 2s - loss: 0.3255 - auc_9: 0.9332 - accuracy: 0.8459 - val_loss: 0.3321 - val_auc_9: 0.9310 - val_accuracy: 0.8405 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 14/200\n",
      "263/263 - 2s - loss: 0.3241 - auc_9: 0.9339 - accuracy: 0.8470 - val_loss: 0.3345 - val_auc_9: 0.9307 - val_accuracy: 0.8430 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "263/263 - 2s - loss: 0.3221 - auc_9: 0.9347 - accuracy: 0.8480 - val_loss: 0.3723 - val_auc_9: 0.9135 - val_accuracy: 0.8172 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "263/263 - 2s - loss: 0.3212 - auc_9: 0.9350 - accuracy: 0.8495 - val_loss: 0.3525 - val_auc_9: 0.9233 - val_accuracy: 0.8311 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "263/263 - 2s - loss: 0.3195 - auc_9: 0.9358 - accuracy: 0.8498 - val_loss: 0.3419 - val_auc_9: 0.9279 - val_accuracy: 0.8375 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "263/263 - 2s - loss: 0.3182 - auc_9: 0.9362 - accuracy: 0.8494 - val_loss: 0.3684 - val_auc_9: 0.9169 - val_accuracy: 0.8186 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "263/263 - 1s - loss: 0.3160 - auc_9: 0.9371 - accuracy: 0.8516 - val_loss: 0.3411 - val_auc_9: 0.9274 - val_accuracy: 0.8375 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "263/263 - 1s - loss: 0.3150 - auc_9: 0.9376 - accuracy: 0.8525 - val_loss: 0.3504 - val_auc_9: 0.9240 - val_accuracy: 0.8344 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "263/263 - 2s - loss: 0.3138 - auc_9: 0.9380 - accuracy: 0.8531 - val_loss: 0.3539 - val_auc_9: 0.9217 - val_accuracy: 0.8272 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "263/263 - 1s - loss: 0.3115 - auc_9: 0.9390 - accuracy: 0.8540 - val_loss: 0.3431 - val_auc_9: 0.9284 - val_accuracy: 0.8379 - lr: 0.0010 - 1s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "263/263 - 2s - loss: 0.3114 - auc_9: 0.9389 - accuracy: 0.8526 - val_loss: 0.3597 - val_auc_9: 0.9216 - val_accuracy: 0.8240 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "263/263 - 2s - loss: 0.3099 - auc_9: 0.9396 - accuracy: 0.8551 - val_loss: 0.3423 - val_auc_9: 0.9309 - val_accuracy: 0.8463 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "263/263 - 2s - loss: 0.3084 - auc_9: 0.9401 - accuracy: 0.8557 - val_loss: 0.3654 - val_auc_9: 0.9200 - val_accuracy: 0.8213 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "263/263 - 2s - loss: 0.3063 - auc_9: 0.9410 - accuracy: 0.8557 - val_loss: 0.3619 - val_auc_9: 0.9223 - val_accuracy: 0.8270 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 26: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  44.7s\n",
      "263/263 - 1s - loss: 0.5203 - auc_9: 0.8266 - accuracy: 0.7524 - 1s/epoch - 5ms/step\n",
      "[CV] END model__activationA=sigmoid, model__activationB=elu, model__dropout=0, model__layers=5, model__n_dense=32, model__optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001E380045760>, model__regL1=0, model__regL2=0; total time=  46.0s\n",
      "Epoch 1/200\n",
      "329/329 - 3s - loss: 0.4608 - auc_10: 0.8635 - accuracy: 0.7782 - val_loss: 0.4266 - val_auc_10: 0.8898 - val_accuracy: 0.7902 - lr: 0.0010 - 3s/epoch - 10ms/step\n",
      "Epoch 2/200\n",
      "329/329 - 2s - loss: 0.3755 - auc_10: 0.9127 - accuracy: 0.8293 - val_loss: 0.3844 - val_auc_10: 0.9088 - val_accuracy: 0.8108 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
      "Epoch 3/200\n",
      "329/329 - 3s - loss: 0.3641 - auc_10: 0.9176 - accuracy: 0.8325 - val_loss: 0.3651 - val_auc_10: 0.9169 - val_accuracy: 0.8217 - lr: 0.0010 - 3s/epoch - 8ms/step\n",
      "Epoch 4/200\n",
      "329/329 - 2s - loss: 0.3559 - auc_10: 0.9211 - accuracy: 0.8361 - val_loss: 0.3634 - val_auc_10: 0.9158 - val_accuracy: 0.8184 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "329/329 - 2s - loss: 0.3464 - auc_10: 0.9253 - accuracy: 0.8424 - val_loss: 0.4029 - val_auc_10: 0.8997 - val_accuracy: 0.8002 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "329/329 - 2s - loss: 0.3413 - auc_10: 0.9275 - accuracy: 0.8450 - val_loss: 0.3788 - val_auc_10: 0.9101 - val_accuracy: 0.8121 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "329/329 - 2s - loss: 0.3352 - auc_10: 0.9301 - accuracy: 0.8483 - val_loss: 0.3738 - val_auc_10: 0.9153 - val_accuracy: 0.8199 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "329/329 - 2s - loss: 0.3320 - auc_10: 0.9315 - accuracy: 0.8495 - val_loss: 0.4338 - val_auc_10: 0.8973 - val_accuracy: 0.7937 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "329/329 - 2s - loss: 0.3280 - auc_10: 0.9332 - accuracy: 0.8509 - val_loss: 0.3636 - val_auc_10: 0.9165 - val_accuracy: 0.8194 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "329/329 - 2s - loss: 0.3255 - auc_10: 0.9343 - accuracy: 0.8536 - val_loss: 0.4135 - val_auc_10: 0.8977 - val_accuracy: 0.7963 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "329/329 - 2s - loss: 0.3236 - auc_10: 0.9350 - accuracy: 0.8542 - val_loss: 0.4039 - val_auc_10: 0.9026 - val_accuracy: 0.8023 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "329/329 - 2s - loss: 0.3209 - auc_10: 0.9361 - accuracy: 0.8561 - val_loss: 0.4181 - val_auc_10: 0.8996 - val_accuracy: 0.7947 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "329/329 - 2s - loss: 0.3175 - auc_10: 0.9376 - accuracy: 0.8576 - val_loss: 0.4084 - val_auc_10: 0.9019 - val_accuracy: 0.7990 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "329/329 - 2s - loss: 0.3149 - auc_10: 0.9386 - accuracy: 0.8590 - val_loss: 0.4629 - val_auc_10: 0.8815 - val_accuracy: 0.7742 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "329/329 - 2s - loss: 0.3154 - auc_10: 0.9383 - accuracy: 0.8573 - val_loss: 0.3770 - val_auc_10: 0.9135 - val_accuracy: 0.8164 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "329/329 - 2s - loss: 0.3127 - auc_10: 0.9394 - accuracy: 0.8592 - val_loss: 0.3999 - val_auc_10: 0.9078 - val_accuracy: 0.8070 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "329/329 - 2s - loss: 0.3095 - auc_10: 0.9406 - accuracy: 0.8607 - val_loss: 0.3871 - val_auc_10: 0.9139 - val_accuracy: 0.8145 - lr: 0.0010 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "329/329 - 2s - loss: 0.3087 - auc_10: 0.9409 - accuracy: 0.8627 - val_loss: 0.3806 - val_auc_10: 0.9127 - val_accuracy: 0.8115 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "329/329 - 2s - loss: 0.3069 - auc_10: 0.9416 - accuracy: 0.8614 - val_loss: 0.3872 - val_auc_10: 0.9105 - val_accuracy: 0.8106 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "329/329 - 2s - loss: 0.3050 - auc_10: 0.9423 - accuracy: 0.8629 - val_loss: 0.4139 - val_auc_10: 0.9051 - val_accuracy: 0.8004 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "329/329 - 2s - loss: 0.3031 - auc_10: 0.9431 - accuracy: 0.8650 - val_loss: 0.4272 - val_auc_10: 0.8960 - val_accuracy: 0.7875 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "329/329 - 2s - loss: 0.3018 - auc_10: 0.9436 - accuracy: 0.8650 - val_loss: 0.4155 - val_auc_10: 0.9041 - val_accuracy: 0.7965 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "329/329 - 2s - loss: 0.2991 - auc_10: 0.9446 - accuracy: 0.8659 - val_loss: 0.3881 - val_auc_10: 0.9145 - val_accuracy: 0.8151 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "329/329 - 2s - loss: 0.2980 - auc_10: 0.9450 - accuracy: 0.8649 - val_loss: 0.4015 - val_auc_10: 0.9077 - val_accuracy: 0.8059 - lr: 0.0010 - 2s/epoch - 6ms/step\n",
      "Epoch 24: early stopping\n",
      "[Pipeline] ............. (step 1 of 1) Processing model, total=  48.9s\n"
     ]
    }
   ],
   "source": [
    "# Treinamento\n",
    "\n",
    "fit_params = {\n",
    "    'model__batch_size': batch_size,\n",
    "    'model__epochs': epochs,\n",
    "    'model__verbose': verbose,\n",
    "    'model__validation_data': (x_teste, y_teste),\n",
    "    'model__shuffle': True,\n",
    "    'model__validation_steps': None,\n",
    "    'model__validation_freq': 1,\n",
    "}\n",
    "\n",
    "grid_result = grid.fit(x_treino, y_treino, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4885, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>model__activationA</th>\n",
       "      <th>model__activationB</th>\n",
       "      <th>model__dropout</th>\n",
       "      <th>model__layers</th>\n",
       "      <th>model__n_dense</th>\n",
       "      <th>model__optimizer</th>\n",
       "      <th>model__regL1</th>\n",
       "      <th>model__regL2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803704</td>\n",
       "      <td>47.785747</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.802039</td>\n",
       "      <td>45.879516</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>elu</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;keras.optimizers.optimizer_v2.adam.Adam objec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score  mean_fit_time model__activationA  \\\n",
       "rank_test_score                                                      \n",
       "1                       0.803704      47.785747            sigmoid   \n",
       "2                       0.802039      45.879516            sigmoid   \n",
       "\n",
       "                model__activationB  model__dropout  model__layers  \\\n",
       "rank_test_score                                                     \n",
       "1                              elu               0              5   \n",
       "2                              elu               0              4   \n",
       "\n",
       "                 model__n_dense  \\\n",
       "rank_test_score                   \n",
       "1                            32   \n",
       "2                            32   \n",
       "\n",
       "                                                  model__optimizer  \\\n",
       "rank_test_score                                                      \n",
       "1                <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
       "2                <keras.optimizers.optimizer_v2.adam.Adam objec...   \n",
       "\n",
       "                 model__regL1  model__regL2  \n",
       "rank_test_score                              \n",
       "1                           0             0  \n",
       "2                           0             0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado do SearchGridCV\n",
    "\n",
    "pd.concat([\n",
    "           pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']],\n",
    "           pd.DataFrame(grid.cv_results_['params'])\n",
    "          ],\n",
    "           axis=1,\n",
    "           join='inner').set_index('rank_test_score').sort_values('rank_test_score')\n",
    "\n",
    "# Função score com base no SearchGridCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid.best_params_\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1315/1315 - 5s - loss: 0.3486 - auc_10: 0.9247 - accuracy: 0.8404 - 5s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8403956890106201"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CategoricalCrossentropy, AUC e Accuracy - Função score do Modelo Keras encapsulado\n",
    "best_model.score(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 - 1s - loss: 0.3634 - auc_10: 0.9158 - accuracy: 0.8184 - 554ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8184237480163574"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CategoricalCrossentropy, AUC e Accuracy - Função score do Modelo Keras encapsulado\n",
    "best_model.score(x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise n - XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento de Dados Para Construção de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Construção, Treinamento e Avaliação do Modelo 1 com Regressão Linear (Benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resíduos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Construção, Treinamento e Avaliação do Modelo n com XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
