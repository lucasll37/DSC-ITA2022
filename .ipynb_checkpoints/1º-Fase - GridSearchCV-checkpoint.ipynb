{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Challenge @ ITA 2022</font>\n",
    "# <font color='blue'>Equipe DIOMGIS</font>\n",
    "\n",
    "## <font color='blue'>1º Fase</font>\n",
    "\n",
    "### <font color='blue'>Predição de pregões futuros de ativos que compõem o índice SP500.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](data\\image\\logo.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas e Frameworks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.losses import MeanSquaredError\n",
    "from tensorboard import notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Equipe DIOMGIS\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirma se o TensorFlow pode acessar a GPU\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "    raise SystemError('GPU device not found')\n",
    "    \n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado da GPU\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros fixos de treinamento\n",
    "\n",
    "verbose = 2\n",
    "seed = 25\n",
    "steps = 30\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "nKFold = 5\n",
    "logRetPeriod = 20\n",
    "graphic = False\n",
    "downloadData = False\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ['2022-10-24', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', \n",
    "            '2022-10-31', '2022-11-01', '2022-11-02', '2022-11-03', '2022-11-04', \n",
    "            '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11',\n",
    "            '2022-11-14', '2022-11-15', '2022-11-16', '2022-11-17', '2022-11-18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setores = {\n",
    "    'Industrials': ['MMM', 'AOS', 'ALK', 'ALLE', 'AAL', 'AME', 'BA',\n",
    "                    'CHRW', 'CARR', 'CAT', 'CTAS', 'CPRT', 'CSGP',\n",
    "                    'CSX', 'CMI', 'DE', 'DAL', 'DOV', 'ETN', 'EMR',\n",
    "                    'EFX', 'EXPD', 'FAST', 'FDX', 'FTV', 'FBHS',\n",
    "                    'GNRC', 'GD', 'GE', 'HON', 'HWM', 'HII', 'IEX',\n",
    "                    'ITW', 'IR', 'JBHT', 'J', 'JCI', 'LHX', 'LDOS',\n",
    "                    'LMT', 'MAS', 'NDSN', 'NSC', 'NOC', 'ODFL',\n",
    "                    'OTIS', 'PCAR', 'PH', 'PNR', 'PWR', 'RTX', 'RSG',\n",
    "                    'RHI', 'ROK', 'ROL', 'SNA', 'LUV', 'SWK', 'TXT',\n",
    "                    'TT', 'TDG', 'UNP', 'UAL', 'UPS', 'URI', 'VRSK',\n",
    "                    'WAB', 'WM', 'GWW', 'XYL'],\n",
    "    \n",
    "    'HealthCare': ['ABT', 'ABBV', 'ABMD', 'A', 'ALGN', 'ABC', 'AMGN',\n",
    "                   'BAX', 'BDX', 'BIO', 'TECH', 'BIIB', 'BSX', 'BMY',\n",
    "                   'CAH', 'CTLT', 'CNC', 'CRL', 'CI', 'COO', 'CVS',\n",
    "                   'DHR', 'DVA', 'XRAY', 'DXCM', 'EW', 'ELV', 'LLY',\n",
    "                   'GILD', 'HCA', 'HSIC', 'HOLX', 'HUM', 'IDXX',\n",
    "                   'ILMN', 'INCY', 'ISRG', 'IQV', 'JNJ', 'LH', 'MCK',\n",
    "                   'MDT', 'MRK', 'MTD', 'MRNA', 'MOH', 'OGN', 'PKI',\n",
    "                   'PFE', 'DGX', 'REGN', 'RMD', 'STE', 'SYK', 'TFX',\n",
    "                   'TMO', 'UNH', 'UHS', 'VRTX', 'VTRS', 'WAT',\n",
    "                   'WST', 'ZBH', 'ZTS'],\n",
    "    \n",
    "    'InformationTechnology': ['ACN', 'ADBE', 'ADP', 'AKAM', 'AMD', 'APH',\n",
    "                              'ADI', 'ANSS', 'AAPL', 'AMAT', 'ANET', 'ADSK',\n",
    "                              'AVGO', 'BR', 'CDNS', 'CDW', 'CDAY', 'CSCO',\n",
    "                              'CTSH', 'GLW', 'DXC', 'ENPH', 'EPAM', 'FFIV',\n",
    "                              'FIS', 'FISV', 'FLT', 'FTNT', 'IT', 'GPN',\n",
    "                              'HPE', 'HPQ', 'IBM', 'INTC', 'INTU', 'JKHY',\n",
    "                              'JNPR', 'KEYS', 'KLAC', 'LRCX', 'MA', 'MCHP',\n",
    "                              'MU', 'MSFT', 'MPWR', 'MSI', 'NTAP', 'NLOK',\n",
    "                              'NVDA', 'NXPI', 'ON', 'ORCL', 'PAYX', 'PAYC',\n",
    "                              'PYPL', 'PTC', 'QRVO', 'QCOM', 'ROP', 'CRM',\n",
    "                              'STX', 'NOW', 'SWKS', 'SEDG', 'SNPS', 'TEL',\n",
    "                              'TDY', 'TER', 'TXN', 'TRMB', 'TYL', 'VRSN',\n",
    "                              'V', 'WDC', 'ZBRA'],\n",
    "    \n",
    "    'CommunicationServices': ['ATVI', 'GOOGL', 'GOOG', 'T', 'CHTR', 'CMCSA',\n",
    "                              'DISH', 'DIS', 'EA', 'FOXA', 'FOX', 'IPG', 'LYV',\n",
    "                              'LUMN', 'MTCH', 'META', 'NFLX', 'NWSA', 'NWS',\n",
    "                              'OMC', 'PARA', 'TMUS', 'TTWO', 'TWTR', 'VZ', 'WBD'],\n",
    "    \n",
    "    'ConsumerStaples': ['ADM', 'MO', 'BF.B', 'CPB', 'CHD', 'CLX', 'KO', 'CL',\n",
    "                        'CAG', 'STZ', 'COST', 'EL', 'GIS', 'HSY', 'HRL', 'K',\n",
    "                        'KDP', 'KMB', 'KHC', 'KR', 'LW', 'MKC', 'TAP', 'MDLZ',\n",
    "                        'MNST', 'PEP', 'PM', 'PG', 'SJM', 'SYY', 'TSN', 'WBA',\n",
    "                        'WMT'],\n",
    "    \n",
    "    'ConsumerDiscretionary': ['AAP', 'AMZN', 'APTV', 'AZO', 'BBWI',\n",
    "                              'BBY', 'BKNG', 'BWA', 'CZR', 'KMX', 'CCL',\n",
    "                              'CMG', 'DHI', 'DRI', 'DG', 'DLTR',\n",
    "                              'DPZ', 'EBAY', 'ETSY', 'EXPE', 'F',\n",
    "                              'GRMN', 'GM', 'GPC', 'HAS', 'HLT', 'HD',\n",
    "                              'LVS', 'LEN', 'LKQ', 'LOW', 'MAR', 'MCD',\n",
    "                              'MGM', 'MHK', 'NWL', 'NKE', 'NCLH', 'NVR',\n",
    "                              'ORLY', 'POOL', 'PHM', 'RL', 'ROST', 'RCL',\n",
    "                              'SBUX', 'TPR', 'TGT', 'TSLA', 'TJX',\n",
    "                              'TSCO', 'ULTA', 'VFC', 'WHR', 'WYNN', 'YUM'],\n",
    "    \n",
    "    'Utilities': ['AES', 'LNT', 'AEE', 'AEP', 'AWK', 'ATO', 'CNP',\n",
    "                  'CMS', 'ED', 'CEG', 'D', 'DTE', 'DUK', 'EIX',\n",
    "                  'ETR', 'EVRG', 'ES', 'EXC', 'FE', 'NEE', 'NI',\n",
    "                  'NRG', 'PCG', 'PNW', 'PPL', 'PEG', 'SRE', 'SO',\n",
    "                  'WEC', 'XEL'],\n",
    "    \n",
    "    'Financials': ['AFL', 'ALL', 'AXP', 'AIG', 'AMP', 'AON', 'AJG',\n",
    "                   'AIZ', 'BAC', 'WRB', 'BRK.B', 'BLK', 'BK', 'BRO',\n",
    "                   'COF', 'CBOE', 'SCHW', 'CB', 'CINF', 'C', 'CFG',\n",
    "                   'CME', 'CMA', 'DFS', 'RE', 'FDS', 'FITB', 'FRC',\n",
    "                   'BEN', 'GL', 'GS', 'HIG', 'HBAN', 'ICE', 'IVZ',\n",
    "                   'JPM', 'KEY', 'LNC', 'L', 'MTB', 'MKTX', 'MMC',\n",
    "                   'MET', 'MCO', 'MS', 'MSCI', 'NDAQ', 'NTRS', 'PNC',\n",
    "                   'PFG', 'PGR', 'PRU', 'RJF', 'RF', 'SPGI', 'SBNY',\n",
    "                   'STT', 'SIVB', 'SYF', 'TROW', 'TRV', 'TFC',\n",
    "                   'USB', 'WFC', 'WTW', 'ZION',  'NLSN'],\n",
    "    \n",
    "    'Materials': ['APD', 'ALB', 'AMCR', 'AVY', 'BALL', 'CE', 'CF',\n",
    "                  'CTVA', 'DOW', 'DD', 'EMN', 'ECL', 'FMC', 'FCX',\n",
    "                  'IP', 'IFF', 'LIN', 'LYB', 'MLM', 'MOS', 'NEM',\n",
    "                  'NUE', 'PKG', 'PPG', 'SEE', 'SHW', 'VMC', 'WRK'],\n",
    "    \n",
    "    'RealEstate': ['ARE', 'AMT', 'AVB', 'BXP', 'CPT', 'CBRE', 'CCI',\n",
    "                   'DLR', 'EQIX', 'EQR', 'ESS', 'EXR', 'FRT', 'PEAK',\n",
    "                   'HST', 'INVH', 'IRM', 'KIM', 'MAA', 'PLD', 'PSA',\n",
    "                   'O', 'REG', 'SBAC', 'SPG', 'UDR', 'VTR', 'VICI',\n",
    "                   'VNO', 'WELL', 'WY'],\n",
    "    \n",
    "    'Energy': ['APA','BKR', 'CVX', 'COP', 'CTRA', 'DVN', 'FANG', 'EOG',\n",
    "               'EQT', 'XOM', 'HAL', 'HES', 'KMI', 'MRO', 'MPC', 'OXY',\n",
    "               'OKE', 'PSX', 'PXD', 'SLB', 'VLO', 'WMB']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ativos = []\n",
    "for setor, empresas in setores.items():\n",
    "    ativos.extend(empresas)\n",
    "    \n",
    "ativos.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if downloadData:\n",
    "\n",
    "    start_date = \"2017-10-21\"\n",
    "    end_date = \"2022-10-21\"\n",
    "\n",
    "    data = web.DataReader(name = '^GSPC', data_source = 'yahoo', start = start_date, end = end_date)\n",
    "    SP500_index = pd.DataFrame(data['Close']).reset_index().rename(columns={'Close': 'SP500', 'Date': 'Dia'})\n",
    "\n",
    "    SP500_close = pd.DataFrame()\n",
    "\n",
    "    for ativo in ativos:\n",
    "  \n",
    "        if ativo == 'BF.B':\n",
    "            ativo = 'BF-B'\n",
    "\n",
    "        if ativo == 'BRK.B':\n",
    "            ativo = 'BRK-B'\n",
    "\n",
    "        data = web.DataReader(name = ativo, data_source = 'yahoo', start = start_date, end = end_date)\n",
    "        temp_close = pd.DataFrame(data['Close'])\n",
    "        SP500_close = pd.concat([SP500_close, temp_close], axis = 1)\n",
    "\n",
    "        \n",
    "    SP500_close.columns = ativos\n",
    "    SP500_close.reset_index(inplace = True)\n",
    "    SP500_close.rename(columns={'Date': 'Dia'}, inplace = True)\n",
    "\n",
    "    outdir = './data/{}-{}'.format(start_date, end_date)\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    SP500_close.to_csv(path_or_buf = os.path.join(outdir, 'SP500_close'), index = False)\n",
    "    SP500_index.to_csv(path_or_buf = os.path.join(outdir, 'SP500_index'), index = False)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    SP500_close = pd.read_csv('data/SP500_close')\n",
    "    SP500_index = pd.read_csv('data/SP500_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatorTimeframeTable(table, ativo):\n",
    "    \n",
    "    nameColumns = []\n",
    "\n",
    "    for i in range(steps,-1,-1):\n",
    "        nameColumns.append('Close-{}'.format(i))\n",
    "    \n",
    "    TimeframeTable = pd.DataFrame(np.zeros((len(table[ativo])-steps, steps+1), dtype='float64'), columns = nameColumns)\n",
    "\n",
    "    for index, close in enumerate(table[ativo]):\n",
    "        tempA = index\n",
    "        tempB = 0\n",
    "        for i in range(steps+1):\n",
    "            if tempA < len(table[ativo])-steps and tempA >=0:\n",
    "                TimeframeTable.iloc[tempA, tempB] = close\n",
    "\n",
    "            tempA -= 1\n",
    "            tempB += 1\n",
    "\n",
    "    timeIndex = table.iloc[steps:,0]\n",
    "    TimeframeTable[\"Dia\"] = timeIndex.to_numpy()\n",
    "    TimeframeTable.set_index(\"Dia\", inplace = True)\n",
    "    \n",
    "    return TimeframeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainScaler(df):\n",
    "    \n",
    "    trainScaler = pd.DataFrame()\n",
    " \n",
    "    for _ in range(steps+1):\n",
    "        temp_close = pd.DataFrame(df.iloc[:,-1])\n",
    "        trainScaler = pd.concat([trainScaler, temp_close], axis = 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaler.fit(trainScaler)\n",
    "\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessingdata(steps, df, ativos):\n",
    "    \n",
    "    nameColumns = []\n",
    "\n",
    "    for i in range(steps,-1,-1):\n",
    "        nameColumns.append('Close-{}'.format(i))\n",
    "    \n",
    "\n",
    "    aux = []\n",
    "    \n",
    "    for ativo in ativos:\n",
    "        trainDataAtivo = generatorTimeframeTable(df, ativo)\n",
    "        trainDataAtivo.dropna(axis = 0, inplace = True)\n",
    "        \n",
    "        #----Score-Z--------------------------------------\n",
    "        scaler = createTrainScaler(trainDataAtivo)\n",
    "        trainDataAtivo = scaler.transform(trainDataAtivo)\n",
    "        #-------------------------------------------------\n",
    "        aux.append(trainDataAtivo)\n",
    "    \n",
    "    trainData = np.concatenate(tuple(aux), axis=0)\n",
    "    \n",
    "    X = trainData[:, :-1]\n",
    "    y = trainData[:, -1]\n",
    "    \n",
    "\n",
    "    #------Divisão de dados entre Treino e Validação------------------------------------------------\n",
    "    \n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.2, shuffle = False)\n",
    "\n",
    "    X_treino = X_treino.reshape((-1, steps, 1))\n",
    "    X_teste = X_teste.reshape((-1, steps, 1))\n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return [X_treino, X_teste, y_treino, y_teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_index, ['SP500'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção, Treinamento e Avaliação do Modelo Piloto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "   \n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(datetime.now().strftime('%d-%B-%Ih%Mmin')))\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=20,\n",
    "                          verbose = verbose,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              mode=\"min\",\n",
    "                              verbose = verbose,\n",
    "                              min_delta=0.0001,\n",
    "                              min_lr=0)\n",
    "\n",
    "callbacks = [tensorboard, earlystop, reduce_lr, TerminateOnNaN()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer, layers, n_lstm, dropoutFoward):\n",
    "     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(n_lstm,\n",
    "                   activation = 'tanh',\n",
    "                   recurrent_activation = 'sigmoid',\n",
    "                   return_sequences = True,\n",
    "                   input_shape = (steps, 1)))  \n",
    "\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    for layer in range(layers):\n",
    "                \n",
    "        model.add(Dropout(dropoutFoward))\n",
    "        \n",
    "        model.add(LSTM(n_lstm,\n",
    "                       activation = 'tanh',\n",
    "                       recurrent_activation = 'sigmoid',\n",
    "                       return_sequences = True))  \n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    \n",
    "    model.add(LSTM(n_lstm,\n",
    "                   activation = 'tanh',\n",
    "                   recurrent_activation = 'sigmoid',\n",
    "                   return_sequences = False)) \n",
    "    \n",
    "    \n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    Lmse = MeanSquaredError()\n",
    "\n",
    "    model.compile(loss= Lmse, optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "model = KerasRegressor(build_fn = create_model,\n",
    "                        verbose = verbose,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "\n",
    "estimator = Pipeline([(\"model\", model)], verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos parametros (GridSearch)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "opt_SGD = SGD(\n",
    "    learning_rate = learning_rate,\n",
    "    momentum = 0.0,\n",
    "    nesterov = False)\n",
    "\n",
    "opt_RMSprop = RMSprop(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.9,\n",
    "    momentum = 0.0,\n",
    "    epsilon = 1e-07,\n",
    "    centered = False)\n",
    "\n",
    "opt_Adam = Adam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07,\n",
    "    amsgrad = False)\n",
    "\n",
    "opt_Adadelta = Adadelta(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.95,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adagrad = Adagrad(\n",
    "    learning_rate = learning_rate,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adamax = Adamax(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Nadam = Nadam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Ftrl = Ftrl(\n",
    "    learning_rate = learning_rate,\n",
    "    learning_rate_power = -0.5,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    l1_regularization_strength = 0.0,\n",
    "    l2_regularization_strength = 0.0,\n",
    "    l2_shrinkage_regularization_strength = 0.0,\n",
    "    beta = 0.0)\n",
    "\n",
    "params_grid = {\n",
    "    # [opt_SGD, opt_RMSprop, opt_Adam, opt_Adadelta, opt_Adagrad, opt_Adamax, opt_Nadam, opt_Ftrl]\n",
    "    'model__optimizer': [opt_Adadelta],\n",
    "    'model__layers': [1], # + 2 Por padrão já possui duas camadas LSTM\n",
    "    'model__n_lstm': [160],\n",
    "    'model__dropoutFoward': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search e Cross Validation\n",
    "\n",
    "grid = GridSearchCV(estimator = estimator,\n",
    "                    scoring = 'neg_root_mean_squared_error',\n",
    "                    verbose = verbose,\n",
    "                    return_train_score = False,\n",
    "                    cv = nKFold,\n",
    "                    # n_jobs = -2 # \"-2\": mantem 1 processador livre\n",
    "                    # pre_dispatch = '2*n_jobs',\n",
    "                    refit = True,\n",
    "                    param_grid = params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitoramento de Otimização\n",
    "\n",
    "# tensorboard --logdir logs\n",
    "# notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "\n",
    "fit_params = {\n",
    "    'model__batch_size': batch_size,\n",
    "    'model__epochs': epochs,\n",
    "    'model__verbose': verbose,\n",
    "    'model__validation_data': (X_teste, y_teste),\n",
    "    'model__shuffle': False,\n",
    "    'model__validation_steps': None,\n",
    "    'model__validation_freq': 1,\n",
    "}\n",
    "\n",
    "grid_result = grid.fit(X_treino, y_treino, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado do SearchGridCV\n",
    "\n",
    "pd.concat([\n",
    "           pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']],\n",
    "           pd.DataFrame(grid.cv_results_['params'])\n",
    "          ],\n",
    "           axis=1,\n",
    "           join='inner').set_index('rank_test_score').sort_values('rank_test_score')\n",
    "\n",
    "# Ranqueamento segundo métrica do GridSearchCV: neg_root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid.best_params_\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "scoreTrain = best_model.score(X_treino, y_treino)\n",
    "scoreTest = best_model.score(X_teste, y_teste)\n",
    "\n",
    "print('\\n\\nErro quadrático médio em dados de treinamento: {:.5f}\\n\\nErro quadrático médio em dados de validação: {:.5f}\\n\\n'\\\n",
    "      .format(-scoreTrain, -scoreTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillTableFrame(ativo, tablePrevision, table = SP500_close):\n",
    "    \n",
    "    TimeframeTable = generatorTimeframeTable(table, ativo)\n",
    "    \n",
    "    index_data = TimeframeTable.index\n",
    "    \n",
    "    scaler = createTrainScaler(TimeframeTable)\n",
    "\n",
    "    TimeframeTable = scaler.transform(TimeframeTable)\n",
    "    \n",
    "    nameColumns = []\n",
    "\n",
    "    for i in range(steps,-1,-1):\n",
    "        nameColumns.append('Close-{}'.format(i))\n",
    "\n",
    "    TimeframeTable = pd.DataFrame(TimeframeTable, columns = nameColumns, index = index_data)\n",
    "    \n",
    "    \n",
    "    for day in forecast:\n",
    "        \n",
    "        current_info = TimeframeTable.iloc[-1, 1:].to_numpy()\n",
    "        \n",
    "        standardCurrentInfo = current_info.reshape(1, steps, 1).astype('float32')\n",
    "        \n",
    "        current_forecast = best_model.predict(standardCurrentInfo, verbose=False).reshape(1,)\n",
    "        \n",
    "        new_line = np.concatenate((current_info, current_forecast), axis = 0)\n",
    "        \n",
    "        TimeframeTable = pd.concat([TimeframeTable,\n",
    "                                    pd.DataFrame(new_line.reshape(1, -1),\n",
    "                                                 columns = nameColumns,\n",
    "                                                 index = [day])], axis = 0)\n",
    "        \n",
    "        \n",
    "    index_data = TimeframeTable.index  \n",
    "    \n",
    "    TimeframeTable = scaler.inverse_transform(TimeframeTable)\n",
    "    \n",
    "    TimeframeTable = pd.DataFrame(TimeframeTable, columns = nameColumns, index = index_data)\n",
    "    \n",
    "    TimeframeTable.index = pd.to_datetime(TimeframeTable.index)\n",
    "    \n",
    "    \n",
    "    #--------Popula tabela de previsão---------------------------------------------------\n",
    "    if ativo in ativos:\n",
    "            for day in forecast:\n",
    "                tablePrevision.loc[day, ativo] = TimeframeTable.loc[day, 'Close-0']\n",
    "    #------------------------------------------------------------------------------------\n",
    "   \n",
    "    return TimeframeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popula tabela de log-Retorno e gera gráficos\n",
    "\n",
    "def fillPrediction(tableLogRet, tablePrevision, ativos):\n",
    "    lengthTable = len(tableLogRet)\n",
    "\n",
    "    for ativo in ativos:\n",
    "\n",
    "        TimeframeSPAux = fillTableFrame(ativo, tablePrevision)\n",
    "\n",
    "        #-----------Graphic------------------------------------------------------------------------------------------\n",
    "        if graphic:\n",
    "            \n",
    "            outdir = './graphics/score-{:.4f}-{}'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "            if not os.path.exists(outdir):\n",
    "                os.mkdir(outdir)\n",
    "            \n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(TimeframeSPAux.index[:-len(forecast)], TimeframeSPAux.iloc[:-len(forecast), -1], linewidth=1.0, c = 'b')\n",
    "            ax.plot(TimeframeSPAux.index[-len(forecast):], TimeframeSPAux.iloc[-len(forecast):, -1], linewidth=1.0, c = 'r', ls = '-')\n",
    "            ax.legend(['Atual', 'Previsão'])\n",
    "            ax.set_title('Preço de Fechamento - {}'.format(ativo))\n",
    "            ax.set(xlabel='Tempo (ano)', ylabel='Preço ($)')\n",
    "            nameGraphic = '{}-{}.jpg'.format(ativo, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "            fullname = os.path.join(outdir, nameGraphic)\n",
    "            plt.savefig(fullname)\n",
    "            plt.close(fig)\n",
    "        #------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        #--------Popula tabela de Log Retorno------------------------------------------------------------------------\n",
    "        for n in range(len(forecast)):\n",
    "            tableLogRet.loc[lengthTable-n-1, ativo] = \\\n",
    "            np.log(TimeframeSPAux.iloc[lengthTable-steps-n-1, -1] / TimeframeSPAux.iloc[lengthTable-steps-n-1-logRetPeriod, -1])\n",
    "        #------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria tabela de Previsão\n",
    "\n",
    "update = pd.DataFrame(index = pd.to_datetime(forecast), columns = ativos) \\\n",
    "    .reset_index().rename(columns={'index': 'Dia'})\n",
    "\n",
    "tablePrevision = pd.concat([SP500_close, update], axis = 0, ignore_index = True).set_index('Dia')\n",
    "\n",
    "tablePrevision.index = pd.to_datetime(tablePrevision.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria tabela de Log-Retorno vazia \n",
    "\n",
    "index_data = pd.to_datetime(SP500_close['Dia'].append(pd.Series(forecast)))\n",
    "\n",
    "tableLogRet = pd.DataFrame(index = index_data,\n",
    "                           columns = ativos).reset_index().rename(columns={'index': 'Dia'})\n",
    "\n",
    "tableLogRet['Dia'] = tableLogRet['Dia'].apply(lambda date: date.strftime('%d/%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, ativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableLogRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablePrevision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva tabela de previsão\n",
    "\n",
    "outdirP = './previsao/score-{:.4f}-{}'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "if not os.path.exists(outdirP):\n",
    "    os.mkdir(outdirP)\n",
    "\n",
    "nameTableP = 'predicao.csv'\n",
    "\n",
    "fullnameP = os.path.join(outdirP, nameTableP)\n",
    "\n",
    "tablePrevision.to_csv(fullnameP, index = True, decimal = '.', sep=',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva tabela Entregável do Log-Retorno no padrão\n",
    "\n",
    "outdirLR = './logRetorno/score-{:.4f}-{}'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "if not os.path.exists(outdirLR):\n",
    "    os.mkdir(outdirLR)\n",
    "\n",
    "nameTableLR = 'predicao.csv'\n",
    "\n",
    "fullnameLR = os.path.join(outdirLR, nameTableLR)\n",
    "\n",
    "tableLogRet.iloc[-len(forecast):, :].to_csv(fullnameLR, index = False, decimal = '.', sep=',')       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
