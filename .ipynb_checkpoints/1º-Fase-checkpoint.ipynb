{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Challenge @ ITA 2022</font>\n",
    "# <font color='blue'>Equipe DIOMGIS</font>\n",
    "\n",
    "## <font color='blue'>1º Fase</font>\n",
    "\n",
    "### <font color='blue'>Predição de pregões futuros de ativos que compõem o índice SP500.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](data\\image\\logo.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas e Frameworks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.losses import MeanSquaredError\n",
    "from tensorboard import notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Equipe DIOMGIS\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirma se o TensorFlow pode acessar a GPU\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "    raise SystemError('GPU device not found')\n",
    "    \n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado da GPU\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros fixos de treinamento\n",
    "\n",
    "verbose = 2\n",
    "seed = 25\n",
    "steps = 30\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "nKFold = 5\n",
    "graphic = True\n",
    "logRetPeriod = 20\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ['2022-10-24', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', \n",
    "            '2022-10-31', '2022-11-01', '2022-11-02', '2022-11-03', '2022-11-04', \n",
    "            '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11',\n",
    "            '2022-11-14', '2022-11-15', '2022-11-16', '2022-11-17', '2022-11-18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ativos = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABMD', 'ABT',\n",
    "          'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES',\n",
    "          'AFL', 'AIG', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALK', 'ALL',\n",
    "          'ALLE', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN',\n",
    "          'ANET', 'ANSS', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARE',\n",
    "          'ATO', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXP', 'AZO', 'BA',\n",
    "          'BAC', 'BALL', 'BAX', 'BBWI', 'BBY', 'BDX', 'BEN', 'BF.B', 'BIIB',\n",
    "          'BIO', 'BK', 'BKNG', 'BKR', 'BLK', 'BMY', 'BR', 'BRK.B', 'BRO',\n",
    "          'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CARR', 'CAT', 'CB',\n",
    "          'CBOE', 'CBRE', 'CCI', 'CCL', 'CDAY', 'CDNS', 'CDW', 'CE', 'CEG',\n",
    "          'CF', 'CFG', 'CHD', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX',\n",
    "          'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF',\n",
    "          'COO', 'COP', 'COST', 'CPB', 'CPRT', 'CPT', 'CRL', 'CRM', 'CSCO',\n",
    "          'CSGP', 'CSX', 'CTAS', 'CTLT', 'CTRA', 'CTSH', 'CTVA', 'CVS',\n",
    "          'CVX', 'CZR', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI',\n",
    "          'DHR', 'DIS', 'DISH', 'DLR', 'DLTR', 'DOV', 'DOW', 'DPZ', 'DRI',\n",
    "          'DTE', 'DUK', 'DVA', 'DVN', 'DXC', 'DXCM', 'EA', 'EBAY', 'ECL',\n",
    "          'ED', 'EFX', 'EIX', 'EL', 'ELV', 'EMN', 'EMR', 'ENPH', 'EOG',\n",
    "          'EPAM', 'EQIX', 'EQR', 'EQT', 'ES', 'ESS', 'ETN', 'ETR', 'ETSY',\n",
    "          'EVRG', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FANG', 'FAST',\n",
    "          'FBHS', 'FCX', 'FDS', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB',\n",
    "          'FLT', 'FMC', 'FOX', 'FOXA', 'FRC', 'FRT', 'FTNT', 'FTV', 'GD',\n",
    "          'GE', 'GILD', 'GIS', 'GL', 'GLW', 'GM', 'GNRC', 'GOOG', 'GOOGL',\n",
    "          'GPC', 'GPN', 'GRMN', 'GS', 'GWW', 'HAL', 'HAS', 'HBAN', 'HCA',\n",
    "          'HD', 'HES', 'HIG', 'HII', 'HLT', 'HOLX', 'HON', 'HPE', 'HPQ',\n",
    "          'HRL', 'HSIC', 'HST', 'HSY', 'HUM', 'HWM', 'IBM', 'ICE', 'IDXX',\n",
    "          'IEX', 'IFF', 'ILMN', 'INCY', 'INTC', 'INTU', 'INVH', 'IP', 'IPG',\n",
    "          'IQV', 'IR', 'IRM', 'ISRG', 'IT', 'ITW', 'IVZ', 'J', 'JBHT', 'JCI',\n",
    "          'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KDP', 'KEY', 'KEYS', 'KHC',\n",
    "          'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KR', 'L', 'LDOS', 'LEN',\n",
    "          'LH', 'LHX', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW',\n",
    "          'LRCX', 'LUMN', 'LUV', 'LVS', 'LW', 'LYB', 'LYV', 'MA', 'MAA',\n",
    "          'MAR', 'MAS', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET',\n",
    "          'META', 'MGM', 'MHK', 'MKC', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST',\n",
    "          'MO', 'MOH', 'MOS', 'MPC', 'MPWR', 'MRK', 'MRNA', 'MRO', 'MS',\n",
    "          'MSCI', 'MSFT', 'MSI', 'MTB', 'MTCH', 'MTD', 'MU', 'NCLH', 'NDAQ',\n",
    "          'NDSN', 'NEE', 'NEM', 'NFLX', 'NI', 'NKE', 'NLOK', 'NLSN', 'NOC',\n",
    "          'NOW', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NVR', 'NWL',\n",
    "          'NWS', 'NWSA', 'NXPI', 'O', 'ODFL', 'OGN', 'OKE', 'OMC', 'ON',\n",
    "          'ORCL', 'ORLY', 'OTIS', 'OXY', 'PARA', 'PAYC', 'PAYX', 'PCAR',\n",
    "          'PCG', 'PEAK', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH',\n",
    "          'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'POOL',\n",
    "          'PPG', 'PPL', 'PRU', 'PSA', 'PSX', 'PTC', 'PWR', 'PXD', 'PYPL',\n",
    "          'QCOM', 'QRVO', 'RCL', 'RE', 'REG', 'REGN', 'RF', 'RHI', 'RJF',\n",
    "          'RL', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'SBAC',\n",
    "          'SBNY', 'SBUX', 'SCHW', 'SEDG', 'SEE', 'SHW', 'SIVB', 'SJM', 'SLB',\n",
    "          'SNA', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRE', 'STE', 'STT', 'STX',\n",
    "          'STZ', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYY', 'T', 'TAP', 'TDG',\n",
    "          'TDY', 'TECH', 'TEL', 'TER', 'TFC', 'TFX', 'TGT', 'TJX', 'TMO',\n",
    "          'TMUS', 'TPR', 'TRMB', 'TROW', 'TRV', 'TSCO', 'TSLA', 'TSN', 'TT',\n",
    "          'TTWO', 'TWTR', 'TXN', 'TXT', 'TYL', 'UAL', 'UDR', 'UHS', 'ULTA',\n",
    "          'UNH', 'UNP', 'UPS', 'URI', 'USB', 'V', 'VFC', 'VICI', 'VLO',\n",
    "          'VMC', 'VNO', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VTRS', 'VZ', 'WAB',\n",
    "          'WAT', 'WBA', 'WBD', 'WDC', 'WEC', 'WELL', 'WFC', 'WHR', 'WM',\n",
    "          'WMB', 'WMT', 'WRB', 'WRK', 'WST', 'WTW', 'WY', 'WYNN', 'XEL',\n",
    "          'XOM', 'XRAY', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION', 'ZTS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# >>>>>>>>> Execute trecho comentado somente na primeira vez que rodar o Notebook <<<<<<<<<<\n",
    "#\n",
    "# start_date = \"2017-10-21\"\n",
    "# end_date = \"2022-10-21\"\n",
    "# \n",
    "# data = web.DataReader(name = '^GSPC', data_source = 'yahoo', start = start_date, end = end_date)\n",
    "# SP500_index = pd.DataFrame(data['Close']).reset_index().rename(columns={'Close': 'SP500', 'Date': 'Dia'})\n",
    "# \n",
    "# SP500_close = pd.DataFrame()\n",
    "# \n",
    "# for ativo in ativos:\n",
    "#     \n",
    "#     if ativo == 'BF.B':\n",
    "#         ativo = 'BF-B'\n",
    "#         \n",
    "#     if ativo == 'BRK.B':\n",
    "#         ativo = 'BRK-B'\n",
    "#\n",
    "#     data = web.DataReader(name = ativo, data_source = 'yahoo', start = start_date, end = end_date)\n",
    "#     temp_close = pd.DataFrame(data['Close'])  # .rename(columns={'Close': 'SP500', 'Date': 'Dia'})\n",
    "#     SP500_close = pd.concat([SP500_close, temp_close], axis = 1)\n",
    "# \n",
    "# \n",
    "# SP500_close.columns = ativos # .rename(columns={'Close': 'SP500', 'Date': 'Dia'})\n",
    "# SP500_close.reset_index(inplace = True)\n",
    "# SP500_close.rename(columns={'Date': 'Dia'}, inplace = True)\n",
    "# \n",
    "# assert SP500_close.isna().sum().mean() == 0,  \"Valores Faltantes\"\n",
    "# assert SP500_index.isna().sum().mean() == 0,  \"Valores Faltantes\"\n",
    "# \n",
    "# SP500_close.to_csv(path_or_buf = 'data/SP500_close', index = False)\n",
    "# SP500_index.to_csv(path_or_buf = 'data/SP500_index', index = False)\n",
    "\n",
    "df = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "\n",
    "Industrials = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "HealthCare = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "InformationTechnology = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "CommunicationServices = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "ConsumerStaples = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "ConsumerDiscretionary = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "Utilities = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "Financials = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "Materials = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "RealEstate = df.loc[df['GICS Sector'] == 'Industrials']['Symbol'].tolist()\n",
    "\n",
    "setores = [Industrials, HealthCare, InformationTechnology, CommunicationServices, ConsumerStaples,\n",
    "           ConsumerDiscretionary, Utilities, Financials, Materials, RealEstate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_close = pd.read_csv('data/SP500_close')\n",
    "SP500_index = pd.read_csv('data/SP500_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatorTimeframeTable(table, ativo): # ,nameColumns\n",
    "    TimeframeTable = pd.DataFrame(np.zeros((len(table[ativo])-steps, steps+1), dtype='float64')) # , columns = nameColumns\n",
    "\n",
    "    for index, close in enumerate(table[ativo]):\n",
    "        tempA = index\n",
    "        tempB = 0\n",
    "        for i in range(steps+1):\n",
    "            if tempA < len(table[ativo])-steps and tempA >=0:\n",
    "                TimeframeTable.iloc[tempA, tempB] = close\n",
    "\n",
    "            tempA -= 1\n",
    "            tempB += 1\n",
    "\n",
    "    timeIndex = table.iloc[steps:,0]\n",
    "    TimeframeTable[\"Dia\"] = timeIndex.to_numpy()\n",
    "    TimeframeTable.set_index(\"Dia\", inplace = True)\n",
    "    \n",
    "    return TimeframeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainScaler(df):\n",
    "    \n",
    "    trainScaler = pd.DataFrame()\n",
    " \n",
    "    for _ in range(steps+1):\n",
    "        temp_close = pd.DataFrame(df.iloc[:,-1])\n",
    "        trainScaler = pd.concat([trainScaler, temp_close], axis = 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaler.fit(trainScaler)\n",
    "\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessingdata(steps, df, ativos):\n",
    "    \n",
    "    nameColumns = []\n",
    "\n",
    "    for i in range(steps,-1,-1):\n",
    "        nameColumns.append('Close-{}'.format(i))\n",
    "    \n",
    "\n",
    "    aux = []\n",
    "    \n",
    "    for ativo in ativos:\n",
    "        trainDataAtivo = generatorTimeframeTable(df, ativo)\n",
    "        trainDataAtivo.dropna(axis = 0, inplace = True)\n",
    "        \n",
    "        #----Score-Z--------------------------------------\n",
    "        scaler = createTrainScaler(trainDataAtivo)\n",
    "        trainDataAtivo = scaler.transform(trainDataAtivo)\n",
    "        #-------------------------------------------------\n",
    "        aux.append(trainDataAtivo)\n",
    "    \n",
    "    trainData = np.concatenate(tuple(aux), axis=0)\n",
    "    \n",
    "    X = trainData[:, :-1]\n",
    "    y = trainData[:, -1]\n",
    "    \n",
    "\n",
    "    #------Divisão de dados entre Treino e Validação------------------------------------------------\n",
    "    \n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.2, shuffle = False)\n",
    "\n",
    "    X_treino = X_treino.reshape((-1, steps, 1))\n",
    "    X_teste = X_teste.reshape((-1, steps, 1))\n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    return [X_treino, X_teste, y_treino, y_teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_index, ['SP500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, Industrials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, InformationTechnology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, CommunicationServices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, ConsumerStaples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, ConsumerDiscretionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, Utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, Financials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, Materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = Preprocessingdata(steps, SP500_close, RealEstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção, Treinamento e Avaliação do Modelo Piloto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "   \n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(datetime.now().strftime('%d-%B-%Ih%Mmin')))\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=20,\n",
    "                          verbose = verbose,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              mode=\"min\",\n",
    "                              verbose = verbose,\n",
    "                              min_delta=0.0001,\n",
    "                              min_lr=0)\n",
    "\n",
    "callbacks = [tensorboard, earlystop, reduce_lr, TerminateOnNaN()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer, layers, n_lstm, dropoutFoward):\n",
    "     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(n_lstm,\n",
    "                   activation = 'tanh',\n",
    "                   recurrent_activation = 'sigmoid',\n",
    "                   return_sequences = True,\n",
    "                   input_shape = (steps, 1)))  \n",
    "\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    for layer in range(layers):\n",
    "                \n",
    "        model.add(Dropout(dropoutFoward))\n",
    "        \n",
    "        model.add(LSTM(n_lstm,\n",
    "                       activation = 'tanh',\n",
    "                       recurrent_activation = 'sigmoid',\n",
    "                       return_sequences = True))  \n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    \n",
    "    model.add(LSTM(n_lstm,\n",
    "                   activation = 'tanh',\n",
    "                   recurrent_activation = 'sigmoid',\n",
    "                   return_sequences = False)) \n",
    "    \n",
    "    \n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    Lmse = MeanSquaredError()\n",
    "\n",
    "    model.compile(loss= Lmse, optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "model = KerasRegressor(build_fn = create_model,\n",
    "                        verbose = verbose,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "\n",
    "estimator = Pipeline([(\"model\", model)], verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos parametros (GridSearch)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "opt_SGD = SGD(\n",
    "    learning_rate = learning_rate,\n",
    "    momentum = 0.0,\n",
    "    nesterov = False)\n",
    "\n",
    "opt_RMSprop = RMSprop(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.9,\n",
    "    momentum = 0.0,\n",
    "    epsilon = 1e-07,\n",
    "    centered = False)\n",
    "\n",
    "opt_Adam = Adam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07,\n",
    "    amsgrad = False)\n",
    "\n",
    "opt_Adadelta = Adadelta(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.95,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adagrad = Adagrad(\n",
    "    learning_rate = learning_rate,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adamax = Adamax(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Nadam = Nadam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Ftrl = Ftrl(\n",
    "    learning_rate = learning_rate,\n",
    "    learning_rate_power = -0.5,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    l1_regularization_strength = 0.0,\n",
    "    l2_regularization_strength = 0.0,\n",
    "    l2_shrinkage_regularization_strength = 0.0,\n",
    "    beta = 0.0)\n",
    "\n",
    "params_grid = {\n",
    "    # [opt_SGD, opt_RMSprop, opt_Adam, opt_Adadelta, opt_Adagrad, opt_Adamax, opt_Nadam, opt_Ftrl]\n",
    "    'model__optimizer': [opt_Adadelta],\n",
    "    'model__layers': [1], # + 2 Por padrão já possui duas camadas LSTM\n",
    "    'model__n_lstm': [160],\n",
    "    'model__dropoutFoward': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search e Cross Validation\n",
    "\n",
    "grid = GridSearchCV(estimator = estimator,\n",
    "                    scoring = 'neg_root_mean_squared_error',\n",
    "                    verbose = verbose,\n",
    "                    return_train_score = False,\n",
    "                    cv = nKFold,\n",
    "                    # n_jobs = -2 # \"-2\": mantem 1 processador livre\n",
    "                    # pre_dispatch = '2*n_jobs',\n",
    "                    refit = True,\n",
    "                    param_grid = params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitoramento de Otimização\n",
    "\n",
    "# tensorboard --logdir logs\n",
    "# notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "\n",
    "fit_params = {\n",
    "    'model__batch_size': batch_size,\n",
    "    'model__epochs': epochs,\n",
    "    'model__verbose': verbose,\n",
    "    'model__validation_data': (X_teste, y_teste),\n",
    "    'model__shuffle': False,\n",
    "    'model__validation_steps': None,\n",
    "    'model__validation_freq': 1,\n",
    "}\n",
    "\n",
    "grid_result = grid.fit(X_treino, y_treino, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado do SearchGridCV\n",
    "\n",
    "pd.concat([\n",
    "           pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']],\n",
    "           pd.DataFrame(grid.cv_results_['params'])\n",
    "          ],\n",
    "           axis=1,\n",
    "           join='inner').set_index('rank_test_score').sort_values('rank_test_score')\n",
    "\n",
    "# Ranckeamento segundo métrica do GridSearchCV: neg_root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid.best_params_\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "scoreTrain = best_model.score(X_treino, y_treino)\n",
    "scoreTest = best_model.score(X_teste, y_teste)\n",
    "\n",
    "print('\\n\\nErro quadrático médio em treinamento: {:.5f}\\n\\nErro quadrático médio em Validação: {:.5f}\\n\\n'\\\n",
    "      .format(-scoreTrain, -scoreTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillTableFrame(ativo, tablePrevision, table = SP500_close):\n",
    "    \n",
    "    TimeframeTable = generatorTimeframeTable(table, ativo)\n",
    "    \n",
    "    index_data = TimeframeTable.index\n",
    "    \n",
    "    scaler = createTrainScaler(TimeframeTable)\n",
    "\n",
    "    TimeframeTable = scaler.transform(TimeframeTable)\n",
    "    \n",
    "    nameColumns = []\n",
    "\n",
    "    for i in range(steps,-1,-1):\n",
    "        nameColumns.append('Close-{}'.format(i))\n",
    "\n",
    "    TimeframeTable = pd.DataFrame(TimeframeTable, columns = nameColumns, index = index_data)\n",
    "    \n",
    "    \n",
    "    for day in forecast:\n",
    "        \n",
    "        current_info = TimeframeTable.iloc[-1, 1:].to_numpy()\n",
    "        \n",
    "        standardCurrentInfo = current_info.reshape(1, steps, 1).astype('float32')\n",
    "        \n",
    "        current_forecast = best_model.predict(standardCurrentInfo, verbose=False).reshape(1,)\n",
    "        \n",
    "        new_line = np.concatenate((current_info, current_forecast), axis = 0)\n",
    "        \n",
    "        TimeframeTable = pd.concat([TimeframeTable,\n",
    "                                    pd.DataFrame(new_line.reshape(1, -1),\n",
    "                                                 columns = nameColumns,\n",
    "                                                 index = [day])], axis = 0)\n",
    "        \n",
    "        \n",
    "    index_data = TimeframeTable.index  \n",
    "    \n",
    "    TimeframeTable = scaler.inverse_transform(TimeframeTable)\n",
    "    \n",
    "    TimeframeTable = pd.DataFrame(TimeframeTable, columns = nameColumns, index = index_data)\n",
    "    \n",
    "    TimeframeTable.index = pd.to_datetime(TimeframeTable.index)\n",
    "    \n",
    "    \n",
    "    #--------Popula tabela de previsão---------------------------------------------------\n",
    "    if ativo in ativos:\n",
    "            for day in forecast:\n",
    "                tablePrevision.loc[day, ativo] = TimeframeTable.loc[day, 'Close-0']\n",
    "    #------------------------------------------------------------------------------------\n",
    "   \n",
    "    return TimeframeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeframeSP500  = fillTableFrame('SP500', tablePrevision, table = SP500_index)\n",
    "# pd.to_datetime(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popula tabela de log-Retorno e gera gráficos\n",
    "\n",
    "def fillPrediction(tableLogRet, tablePrevision, ativos):\n",
    "    lengthTable = len(tableLogRet)\n",
    "\n",
    "    outdir = './graphics/score-{:.4f}-{}'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "    for ativo in ativos:\n",
    "\n",
    "        TimeframeSPAux = fillTableFrame(ativo, tablePrevision)\n",
    "\n",
    "        #-----------Graphic------------------------------------------------------------------------------------------\n",
    "        if graphic:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(TimeframeSPAux.index[:-steps], TimeframeSPAux.iloc[:-steps, -1], linewidth=1.0, c = 'b')\n",
    "            ax.plot(TimeframeSPAux.index[-steps:], TimeframeSPAux.iloc[-steps:, -1], linewidth=1.0, c = 'r', ls = '-')\n",
    "            ax.legend(['Atual', 'Previsão'])\n",
    "            ax.set_title('Preço de Fechamento - {}'.format(ativo))\n",
    "            ax.set(xlabel='Tempo (ano)', ylabel='Preço ($)')\n",
    "            nameGraphic = '{}-{}.jpg'.format(ativo, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "            fullname = os.path.join(outdir, nameGraphic)\n",
    "            plt.savefig(fullname)\n",
    "            plt.close(fig)\n",
    "        #------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        #--------Popula tabela de Log Retorno------------------------------------------------------------------------\n",
    "        for n in range(len(forecast)):\n",
    "            tableLogRet.loc[lengthTable-n-1, ativo] = \\\n",
    "            np.log(TimeframeSPAux.iloc[lengthTable-n-1, -1] / TimeframeSPAux.iloc[lengthTable-n-1-logRetPeriod, -1])\n",
    "        #------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria tabela de Previsão\n",
    "\n",
    "update = pd.DataFrame(index = pd.to_datetime(forecast), columns = ativos) \\\n",
    "    .reset_index().rename(columns={'index': 'Dia'})\n",
    "\n",
    "tablePrevision = pd.concat([SP500_close.copy(), update], axis = 0, ignore_index = True).set_index('Dia')\n",
    "\n",
    "tablePrevision.index = pd.to_datetime(tablePrevision.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria tabela de Log-Retorno vazia \n",
    "\n",
    "tableLogRet = pd.DataFrame(index = TimeframeSP500.index,\n",
    "                           columns = ativos).reset_index().rename(columns={'index': 'Dia'})\n",
    "\n",
    "tableLogRet['Dia'] = tableLogRet['Dia'].apply(lambda date: date.strftime('%d/%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, Industrials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, HealthCare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, InformationTechnology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, CommunicationServices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, ConsumerStaples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, ConsumerDiscretionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, Utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, Financials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, Materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillPrediction(tableLogRet, tablePrevision, RealEstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva tabela de previsão\n",
    "\n",
    "outdirP = './previsao/score-{:.4f}-{}'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "if not os.path.exists(outdirP):\n",
    "    os.mkdir(outdirP)\n",
    "\n",
    "nameTableP = 'predicao-score-{:.4f}-{}.csv'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "fullnameP = os.path.join(outdirP, nameTableP)\n",
    "\n",
    "tablePrevision.to_csv(fullnameP, index = True, decimal = '.', sep=',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva tabela Entregável do Log-Retorno no padrão\n",
    "\n",
    "outdirLR = './logRetorno/score-{:.4f}-{}'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "if not os.path.exists(outdirLR):\n",
    "    os.mkdir(outdirLR)\n",
    "\n",
    "nameTableLR = 'predicao-score-{:.4f}-{}.csv'.format(-scoreTest, datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "fullnameLR = os.path.join(outdirLR, nameTableLR)\n",
    "\n",
    "tableLogRet.iloc[-len(forecast):, :].to_csv(fullnameLR, index = False, decimal = '.', sep=',')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação (passado o período de previsão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullnameP = 'previsao/score-0.0826-17-October-12h02min/predicao-score-0.0826-17-October-12h02min.csv'\n",
    "\n",
    "start_date = forecast[0]\n",
    "end_date = forecast[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2022-10-10' # forecast[0]\n",
    "end_date = '2022-10-14' # forecast[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablePrevision = pd.read_csv(fullnameP, index_col = 'Dia')\n",
    "\n",
    "tablePrevision.index = pd.to_datetime(tablePrevision.index)\n",
    "\n",
    "SP500_close_val = pd.DataFrame()\n",
    "\n",
    "outdirV = './graphics/validacao/{}'.format(datetime.now().strftime('%d-%B-%Ih%Mmin'))\n",
    "\n",
    "if not os.path.exists(outdirV):\n",
    "    os.mkdir(outdirV)\n",
    "\n",
    "for ativo in ativos:\n",
    "     \n",
    "    if ativo == 'BF.B':\n",
    "        ativo = 'BF-B'\n",
    "         \n",
    "    if ativo == 'BRK.B':\n",
    "        ativo = 'BRK-B'\n",
    "\n",
    "    data = web.DataReader(name = ativo, data_source = 'yahoo', start = start_date, end = end_date)\n",
    "    temp_close_val = pd.DataFrame(data['Close']).rename(columns={'Close': ativo})\n",
    "    SP500_close_val = pd.concat([SP500_close_val, temp_close_val], axis = 1)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(tablePrevision.loc[start_date:end_date].index, tablePrevision.loc[start_date:end_date, ativo], linewidth=1.0, c = 'b')\n",
    "    \n",
    "    ax.plot(SP500_close_val.loc[start_date:end_date].index, SP500_close_val.loc[start_date:end_date, ativo], linewidth=1.0, c = 'r', ls = '-')\n",
    "    \n",
    "    ax.legend(['Atual', 'Previsão'])\n",
    "    \n",
    "    ax.set_title('Preço de Fechamento - {}'.format(ativo))\n",
    "    \n",
    "    ax.set(xlabel='Tempo (ano)', ylabel = 'Preço ($)')\n",
    "    \n",
    "    nameGraphic = '{}.jpg'.format(ativo)\n",
    "    \n",
    "    fullnameV = os.path.join(outdirV, nameGraphic)\n",
    "    \n",
    "    plt.savefig(fullnameV)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
