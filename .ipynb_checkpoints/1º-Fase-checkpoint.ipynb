{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Challenge @ ITA 2022</font>\n",
    "# <font color='blue'>Equipe DIOMGIS</font>\n",
    "\n",
    "## <font color='blue'>Fase 1</font>\n",
    "\n",
    "### <font color='blue'>Predição de pregões futuros de ativos que compõem o índice SP500.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](data\\image\\logo.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas e Frameworks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorboard import notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Equipe DIOMGIS\n",
      "\n",
      "seaborn          : 0.11.2\n",
      "tensorflow       : 2.10.0\n",
      "tensorboard      : 2.10.0\n",
      "pandas           : 1.4.2\n",
      "numpy            : 1.22.3\n",
      "matplotlib       : 3.5.1\n",
      "keras            : 2.10.0\n",
      "pandas_datareader: 0.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Equipe DIOMGIS\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros fixos de treinamento\n",
    "\n",
    "verbose = 2\n",
    "seed = 25\n",
    "steps = 30\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "nKFold = 5\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Confirma se o TensorFlow pode acessar a GPU\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "    raise SystemError('GPU device not found')\n",
    "    \n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado da GPU\n",
    "\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dos Dados (Execute somente na primeira vez que rodar o Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ['2022-10-24', '2022-10-25', '2022-10-26', '2022-10-27', '2022-10-28', \n",
    "            '2022-10-31', '2022-11-01', '2022-11-02', '2022-11-03', '2022-11-04', \n",
    "            '2022-11-07', '2022-11-08', '2022-11-09', '2022-11-10', '2022-11-11',\n",
    "            '2022-11-14', '2022-11-15', '2022-11-16', '2022-11-17', '2022-11-18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ativos = ['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABMD', 'ABT',\n",
    "       'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES',\n",
    "       'AFL', 'AIG', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALK', 'ALL',\n",
    "       'ALLE', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN',\n",
    "       'ANET', 'ANSS', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARE',\n",
    "       'ATO', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXP', 'AZO', 'BA',\n",
    "       'BAC', 'BALL', 'BAX', 'BBWI', 'BBY', 'BDX', 'BEN', 'BF.B', 'BIIB',\n",
    "       'BIO', 'BK', 'BKNG', 'BKR', 'BLK', 'BMY', 'BR', 'BRK.B', 'BRO',\n",
    "       'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CARR', 'CAT', 'CB',\n",
    "       'CBOE', 'CBRE', 'CCI', 'CCL', 'CDAY', 'CDNS', 'CDW', 'CE', 'CEG',\n",
    "       'CF', 'CFG', 'CHD', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX',\n",
    "       'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF',\n",
    "       'COO', 'COP', 'COST', 'CPB', 'CPRT', 'CPT', 'CRL', 'CRM', 'CSCO',\n",
    "       'CSGP', 'CSX', 'CTAS', 'CTLT', 'CTRA', 'CTSH', 'CTVA', 'CVS',\n",
    "       'CVX', 'CZR', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI',\n",
    "       'DHR', 'DIS', 'DISH', 'DLR', 'DLTR', 'DOV', 'DOW', 'DPZ', 'DRI',\n",
    "       'DTE', 'DUK', 'DVA', 'DVN', 'DXC', 'DXCM', 'EA', 'EBAY', 'ECL',\n",
    "       'ED', 'EFX', 'EIX', 'EL', 'ELV', 'EMN', 'EMR', 'ENPH', 'EOG',\n",
    "       'EPAM', 'EQIX', 'EQR', 'EQT', 'ES', 'ESS', 'ETN', 'ETR', 'ETSY',\n",
    "       'EVRG', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FANG', 'FAST',\n",
    "       'FBHS', 'FCX', 'FDS', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB',\n",
    "       'FLT', 'FMC', 'FOX', 'FOXA', 'FRC', 'FRT', 'FTNT', 'FTV', 'GD',\n",
    "       'GE', 'GILD', 'GIS', 'GL', 'GLW', 'GM', 'GNRC', 'GOOG', 'GOOGL',\n",
    "       'GPC', 'GPN', 'GRMN', 'GS', 'GWW', 'HAL', 'HAS', 'HBAN', 'HCA',\n",
    "       'HD', 'HES', 'HIG', 'HII', 'HLT', 'HOLX', 'HON', 'HPE', 'HPQ',\n",
    "       'HRL', 'HSIC', 'HST', 'HSY', 'HUM', 'HWM', 'IBM', 'ICE', 'IDXX',\n",
    "       'IEX', 'IFF', 'ILMN', 'INCY', 'INTC', 'INTU', 'INVH', 'IP', 'IPG',\n",
    "       'IQV', 'IR', 'IRM', 'ISRG', 'IT', 'ITW', 'IVZ', 'J', 'JBHT', 'JCI',\n",
    "       'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KDP', 'KEY', 'KEYS', 'KHC',\n",
    "       'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KR', 'L', 'LDOS', 'LEN',\n",
    "       'LH', 'LHX', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW',\n",
    "       'LRCX', 'LUMN', 'LUV', 'LVS', 'LW', 'LYB', 'LYV', 'MA', 'MAA',\n",
    "       'MAR', 'MAS', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET',\n",
    "       'META', 'MGM', 'MHK', 'MKC', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST',\n",
    "       'MO', 'MOH', 'MOS', 'MPC', 'MPWR', 'MRK', 'MRNA', 'MRO', 'MS',\n",
    "       'MSCI', 'MSFT', 'MSI', 'MTB', 'MTCH', 'MTD', 'MU', 'NCLH', 'NDAQ',\n",
    "       'NDSN', 'NEE', 'NEM', 'NFLX', 'NI', 'NKE', 'NLOK', 'NLSN', 'NOC',\n",
    "       'NOW', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NVR', 'NWL',\n",
    "       'NWS', 'NWSA', 'NXPI', 'O', 'ODFL', 'OGN', 'OKE', 'OMC', 'ON',\n",
    "       'ORCL', 'ORLY', 'OTIS', 'OXY', 'PARA', 'PAYC', 'PAYX', 'PCAR',\n",
    "       'PCG', 'PEAK', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH',\n",
    "       'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'POOL',\n",
    "       'PPG', 'PPL', 'PRU', 'PSA', 'PSX', 'PTC', 'PWR', 'PXD', 'PYPL',\n",
    "       'QCOM', 'QRVO', 'RCL', 'RE', 'REG', 'REGN', 'RF', 'RHI', 'RJF',\n",
    "       'RL', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'SBAC',\n",
    "       'SBNY', 'SBUX', 'SCHW', 'SEDG', 'SEE', 'SHW', 'SIVB', 'SJM', 'SLB',\n",
    "       'SNA', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRE', 'STE', 'STT', 'STX',\n",
    "       'STZ', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYY', 'T', 'TAP', 'TDG',\n",
    "       'TDY', 'TECH', 'TEL', 'TER', 'TFC', 'TFX', 'TGT', 'TJX', 'TMO',\n",
    "       'TMUS', 'TPR', 'TRMB', 'TROW', 'TRV', 'TSCO', 'TSLA', 'TSN', 'TT',\n",
    "       'TTWO', 'TWTR', 'TXN', 'TXT', 'TYL', 'UAL', 'UDR', 'UHS', 'ULTA',\n",
    "       'UNH', 'UNP', 'UPS', 'URI', 'USB', 'V', 'VFC', 'VICI', 'VLO',\n",
    "       'VMC', 'VNO', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VTRS', 'VZ', 'WAB',\n",
    "       'WAT', 'WBA', 'WBD', 'WDC', 'WEC', 'WELL', 'WFC', 'WHR', 'WM',\n",
    "       'WMB', 'WMT', 'WRB', 'WRK', 'WST', 'WTW', 'WY', 'WYNN', 'XEL',\n",
    "       'XOM', 'XRAY', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION', 'ZTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date = \"2017-10-21\"\n",
    "end_date = \"2022-10-21\"\n",
    "\n",
    "#data = web.DataReader(name = '^GSPC', data_source = 'yahoo', start = start_date, end = end_date)\n",
    "#SP500_index = pd.DataFrame(data['Close']).reset_index().rename(columns={'Close': 'SP500', 'Date': 'Dia'})\n",
    "\n",
    "SP500_close = pd.DataFrame()\n",
    "\n",
    "for ativo in ativos:\n",
    "    data = web.DataReader(name = ativo, data_source = 'yahoo', start = start_date, end = end_date)\n",
    "    temp_close = pd.DataFrame(data['Close'])\n",
    "    SP500_close = pd.concat([SP500_close, temp_close], axis = 1)\n",
    "\n",
    "#SP500_close.columns = ativos\n",
    "#SP500_close.reset_index(inplace = True)\n",
    "#SP500_close.rename(columns={'Date': 'Dia'}, inplace = True)\n",
    "\n",
    "assert SP500_close.isna().sum().mean() == 0,  \"Valores Faltantes\"\n",
    "assert SP500_index.isna().sum().mean() == 0,  \"Valores Faltantes\"\n",
    "\n",
    "#SP500_close.to_csv(path_or_buf = 'data/SP500_close', index = False)\n",
    "#SP500_index.to_csv(path_or_buf = 'data/SP500_index', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_close = pd.read_csv('data/SP500_close')\n",
    "SP500_index = pd.read_csv('data/SP500_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento e Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameColumns = []\n",
    "\n",
    "for i in range(steps,-1,-1):\n",
    "    nameColumns.append('Close-{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatorTimeframeTable(table, ativo):\n",
    "    TimeframeTable = pd.DataFrame(np.zeros((len(table[ativo])-steps, steps+1), dtype='float64'), columns=nameColumns)\n",
    "\n",
    "    for index, close in enumerate(table[ativo]):\n",
    "        tempA = index\n",
    "        tempB = 0\n",
    "        for i in range(steps+1):\n",
    "            if tempA < len(table[ativo])-steps and tempA >=0:\n",
    "                TimeframeTable.iloc[tempA, tempB] = close\n",
    "\n",
    "            tempA -= 1\n",
    "            tempB += 1\n",
    "\n",
    "    timeIndex = table.iloc[steps:,0]\n",
    "    TimeframeTable[\"Dia\"] = timeIndex.to_numpy()\n",
    "    TimeframeTable.set_index(\"Dia\", inplace = True)\n",
    "    \n",
    "    return TimeframeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeframeSP500 = generatorTimeframeTable(SP500_index, 'SP500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeframeSP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeframeSP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = TimeframeSP500['Close-0'].plot(title='SP-500')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Close')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TimeframeSP500.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = TimeframeSP500.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_treino)\n",
    "\n",
    "X_treino = scaler.transform(X_treino)\n",
    "X_teste = scaler.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_treino[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino = X_treino.reshape((-1, steps, 1))\n",
    "X_teste = X_teste.reshape((-1, steps, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Construção, Treinamento e Avaliação do Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "   \n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=20,\n",
    "                          verbose = verbose,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              mode=\"min\",\n",
    "                              verbose = verbose,\n",
    "                              min_delta=0.00001,\n",
    "                              min_lr=0)\n",
    "\n",
    "callbacks = [tensorboard, earlystop, reduce_lr, TerminateOnNaN()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer, layers, n_lstm, dropoutFoward):\n",
    "     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(n_lstm,\n",
    "                   activation = 'tanh',\n",
    "                   recurrent_activation = 'sigmoid',\n",
    "                   return_sequences = True,\n",
    "                   input_shape = (steps, 1)))  \n",
    "\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    for layer in range(layers):\n",
    "                \n",
    "        model.add(Dropout(dropoutFoward))\n",
    "        \n",
    "        model.add(LSTM(n_lstm,\n",
    "                       activation = 'tanh',\n",
    "                       recurrent_activation = 'sigmoid',\n",
    "                       return_sequences = True))  \n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    \n",
    "    model.add(LSTM(n_lstm,\n",
    "                   activation = 'tanh',\n",
    "                   recurrent_activation = 'sigmoid',\n",
    "                   return_sequences = False)) \n",
    "    \n",
    "    \n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    Lmse = keras.losses.MeanSquaredError()\n",
    "\n",
    "    model.compile(loss= Lmse, optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model = KerasRegressor(build_fn = create_model,\n",
    "                        verbose = verbose,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "\n",
    "estimator = Pipeline([(\"model\", model)], verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos parametros (GridSearch)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "opt_SGD = SGD(\n",
    "    learning_rate = learning_rate,\n",
    "    momentum = 0.0,\n",
    "    nesterov = False)\n",
    "\n",
    "opt_RMSprop = RMSprop(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.9,\n",
    "    momentum = 0.0,\n",
    "    epsilon = 1e-07,\n",
    "    centered = False)\n",
    "\n",
    "opt_Adam = Adam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07,\n",
    "    amsgrad = False)\n",
    "\n",
    "opt_Adadelta = Adadelta(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.95,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adagrad = Adagrad(\n",
    "    learning_rate = learning_rate,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adamax = Adamax(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Nadam = Nadam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Ftrl = Ftrl(\n",
    "    learning_rate = learning_rate,\n",
    "    learning_rate_power = -0.5,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    l1_regularization_strength = 0.0,\n",
    "    l2_regularization_strength = 0.0,\n",
    "    l2_shrinkage_regularization_strength = 0.0,\n",
    "    beta = 0.0)\n",
    "\n",
    "params_grid = {\n",
    "    'model__optimizer': [opt_RMSprop],  # [opt_SGD, opt_RMSprop, opt_Adam, opt_Adadelta, opt_Adagrad, opt_Adamax, opt_Nadam, opt_Ftrl]\n",
    "    'model__layers': [3], # + 2 Por padrão já possui duas camadas LSTM\n",
    "    'model__n_lstm': [100],\n",
    "    'model__dropoutFoward': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search e Cross Validation\n",
    "\n",
    "grid = GridSearchCV(estimator = estimator,\n",
    "                    scoring = 'neg_mean_squared_error',\n",
    "                    verbose = verbose,\n",
    "                    return_train_score = False,\n",
    "                    cv = nKFold,\n",
    "                    # n_jobs = -2 # \"-2\": mantem 1 processador livre\n",
    "                    # pre_dispatch = '2*n_jobs',\n",
    "                    refit = True,\n",
    "                    param_grid = params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitoramento de Otimização\n",
    "\n",
    "# tensorboard --logdir=logs/\n",
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "\n",
    "fit_params = {\n",
    "    'model__batch_size': batch_size,\n",
    "    'model__epochs': 1,#epochs,\n",
    "    'model__verbose': verbose,\n",
    "    'model__validation_data': (X_teste, y_teste),\n",
    "    'model__shuffle': False,\n",
    "    'model__validation_steps': None,\n",
    "    'model__validation_freq': 1,\n",
    "}\n",
    "\n",
    "grid_result = grid.fit(X_treino, y_treino, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado do SearchGridCV\n",
    "\n",
    "pd.concat([\n",
    "           pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']],\n",
    "           pd.DataFrame(grid.cv_results_['params'])\n",
    "          ],\n",
    "           axis=1,\n",
    "           join='inner').set_index('rank_test_score').sort_values('rank_test_score')\n",
    "\n",
    "# Função score com base no SearchGridCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid.best_params_\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative mean square error - Função score do Modelo Keras encapsulado\n",
    "best_model.score(X_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative mean square error - Função score do Modelo Keras encapsulado\n",
    "best_model.score(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillTableFrame(ativo, table = SP500_close):\n",
    "    \n",
    "    TimeframeTable = generatorTimeframeTable(table, ativo)\n",
    "    \n",
    "    for day in forecast:\n",
    "        current_info = TimeframeTable.iloc[-1, 1:].to_numpy()\n",
    "        current_forecast = best_model.predict(current_info.reshape(1, steps, 1).astype('float32'), verbose=False).reshape(1,)\n",
    "        new_line = np.concatenate((current_info, current_forecast), axis = 0)\n",
    "        TimeframeTable = pd.concat([TimeframeTable,\n",
    "                                    pd.DataFrame(new_line.reshape(1, -1),\n",
    "                                                 columns = nameColumns,\n",
    "                                                 index = [day])], axis = 0)\n",
    "        \n",
    "    return TimeframeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeframeSP500 = fillTableFrame('SP500', table = SP500_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableRetLog = pd.DataFrame(index = TimeframeSP500.index, columns = ativos).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aativo = ['A', 'AAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthTable = len(tableRetLog)\n",
    "\n",
    "for ativo in aativo:\n",
    "    \n",
    "    TimeframeSPAux = fillTableFrame(ativo)\n",
    "    \n",
    "    for n in range(len(forecast)):\n",
    "        tableRetLog.loc[lengthTable-n-1, ativo] = \\\n",
    "        np.log(TimeframeSPAux.iloc[lengthTable-n-1, -1] / TimeframeSPAux.iloc[lengthTable-n-21, -1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableRetLog.tail(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resíduos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
