{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Challenge @ ITA 2022</font>\n",
    "# <font color='blue'>Equipe DIOMGIS</font>\n",
    "\n",
    "## <font color='blue'>Fase 1</font>\n",
    "\n",
    "### <font color='blue'>TEMA DO DESAFIO</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](..\\data\\image\\logo.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark\n",
    "\n",
    "# Instala o pacote tensorboard-plugin-profile. \n",
    "# Esse pacote é usado para incrementar funcioalidades no Tensorboard.\n",
    "#!pip install -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas e Frameworks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau, LambdaCallback, TerminateOnNaN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier #\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.regularizers import L1L2\n",
    "from tensorboard import notebook\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Equipe DIOMGIS\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 2\n",
    "seed = 25\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirma se o TensorFlow pode acessar a GPU\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "    raise SystemError('GPU device not found')\n",
    "    \n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado da GPU\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerador dados sintéticos\n",
    "\n",
    "size_sample = 200000\n",
    "\n",
    "# Dados de Treino\n",
    "# x\n",
    "x1 = 10 * np.random.random(size_sample)\n",
    "x2 = 10 * np.random.random(size_sample)\n",
    "x3 = 10 * np.random.random(size_sample)\n",
    "x4 = 10 * np.random.random(size_sample)\n",
    "x5 = 10 * np.random.random(size_sample)\n",
    "x6 = 10 * np.random.random(size_sample)\n",
    "x7 = 10 * np.random.random(size_sample)\n",
    "\n",
    "x_treino = np.dstack((x1, x2, x3, x4, x5, x6, x7))[0]\n",
    "\n",
    "# y\n",
    "y_treino = 3*(x1**(1/2)) + 2*(x2**2) + 4*x3 - 5*(x4**(3/2)) + x5 + x6**(3) - x7\n",
    "\n",
    "# Dados de Validação\n",
    "# x\n",
    "x1 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "x2 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "x3 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "x4 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "x5 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "x6 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "x7 = 10 * np.random.random(int(0.1 * size_sample))\n",
    "\n",
    "x_teste = np.dstack((x1, x2, x3, x4, x5, x6, x7))[0]\n",
    "\n",
    "# y\n",
    "y_teste = 3*(x1**(1/2)) + 2*(x2**2) + 4*x3 - 5*(x4**(3/2)) + x5 + x6**(3) - x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros fixos de treinamento\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "nKFold = 5\n",
    "nPCA = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "'''\n",
    "reduceDim = PCA(n_components = nPCA,\n",
    "                # copy = True,\n",
    "                # whiten = False,\n",
    "                # svd_solver = 'auto',\n",
    "                # tol = 0.0,\n",
    "                # iterated_power = 'auto',\n",
    "                # n_oversamples = 10,\n",
    "                # power_iteration_normalizer = 'auto',\n",
    "                # random_state = None\n",
    "               )\n",
    "\n",
    "reduceDim.fit(x_treino)\n",
    "\n",
    "x_treino = reduceDim.transform(x_treino)\n",
    "x_teste = reduceDim.transform(x_teste)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = \"saveModel/bestModel\", \n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             verbose = verbose)\n",
    "    \n",
    "tensorboard = TensorBoard(log_dir=\"logs_reg/{}\".format(time()))\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=20,\n",
    "                              verbose = verbose,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              mode=\"min\",\n",
    "                              verbose = verbose,\n",
    "                              min_delta=0.00001,\n",
    "                              min_lr=0)\n",
    "\n",
    "lambdaCB = LambdaCallback(on_epoch_begin=None,\n",
    "                          on_epoch_end=None,\n",
    "                          on_batch_begin=None,\n",
    "                          on_batch_end=None,\n",
    "                          on_train_begin=None,\n",
    "                          on_train_end=None)\n",
    "\n",
    "callbacks = [tensorboard, earlystop, reduce_lr, TerminateOnNaN()] # checkpoint, lambdaCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer,\n",
    "                 layers,\n",
    "                 n_dense,\n",
    "                 activationA,\n",
    "                 activationB,\n",
    "                 regL1,\n",
    "                 regL2,\n",
    "                 dropout):\n",
    "    \n",
    "    stdInitializer = GlorotUniform(seed)\n",
    "    regularizer = L1L2(l1 = regL1, l2 = regL2)\n",
    "    \n",
    "    activations = [activationA, activationB]\n",
    "    currentActivation = 1\n",
    "    \n",
    "    #----Alternar entre as funções de ativação-----\n",
    "    func = activations[currentActivation]\n",
    "    currentActivation = 1 - currentActivation\n",
    "    #----------------------------------------------\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_dense,\n",
    "                    kernel_initializer = stdInitializer,\n",
    "                    kernel_regularizer = regularizer,\n",
    "                    bias_regularizer = regularizer,\n",
    "                    activation = func,\n",
    "                    input_shape = (nPCA,)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    for layer in range(layers):\n",
    "        \n",
    "        #----Alternar entre as funções de ativação-----\n",
    "        func = activations[currentActivation]\n",
    "        currentActivation = 1 - currentActivation\n",
    "        #----------------------------------------------\n",
    "        \n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(n_dense,\n",
    "                        kernel_initializer = stdInitializer,\n",
    "                        kernel_regularizer = regularizer,\n",
    "                        bias_regularizer = regularizer,\n",
    "                        activation = func))\n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    \n",
    "    model.add(Dense(1,\n",
    "                    kernel_initializer = stdInitializer,\n",
    "                    kernel_regularizer = regularizer,\n",
    "                    bias_regularizer = regularizer,))\n",
    "    \n",
    "    #--------------Loss Function--------------------------\n",
    "    # Lmae = keras.losses.MeanAbsoluteError()\n",
    "    # Lmape = keras.losses.MeanAbsolutePercentageError()\n",
    "    Lmse = keras.losses.MeanSquaredError()\n",
    "    # Lmsle = keras.losses.MeanSquaredLogarithmicError()\n",
    "    #-----------------------------------------------------\n",
    "    #--------------Metric Function------------------------\n",
    "    # Mmae = keras.metrics.MeanAbsoluteError()\n",
    "    # Mmape = keras.metrics.MeanAbsolutePercentageError()\n",
    "    # Mmse = keras.metrics.MeanSquaredError()\n",
    "    # Mmsle = keras.metrics.MeanSquaredLogarithmicError()\n",
    "    # Mrmse = keras.metrics.RootMeanSquaredError()\n",
    "    #-----------------------------------------------------\n",
    "    \n",
    "    \n",
    "    model.compile(loss= Lmse,\n",
    "                  optimizer=optimizer)\n",
    "                  # metrics=[Mmse])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model = KerasRegressor(build_fn = create_model,\n",
    "                        verbose = verbose,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "steps = [(\"model\", model)]\n",
    "\n",
    "estimator = Pipeline(steps, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos parametros (GridSearch)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "opt_SGD = SGD(\n",
    "    learning_rate = learning_rate,\n",
    "    momentum = 0.0,\n",
    "    nesterov = False)\n",
    "\n",
    "opt_RMSprop = RMSprop(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.9,\n",
    "    momentum = 0.0,\n",
    "    epsilon = 1e-07,\n",
    "    centered = False)\n",
    "\n",
    "opt_Adam = Adam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07,\n",
    "    amsgrad = False)\n",
    "\n",
    "opt_Adadelta = Adadelta(\n",
    "    learning_rate = learning_rate,\n",
    "    rho = 0.95,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adagrad = Adagrad(\n",
    "    learning_rate = learning_rate,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Adamax = Adamax(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Nadam = Nadam(\n",
    "    learning_rate = learning_rate,\n",
    "    beta_1 = 0.9,\n",
    "    beta_2 = 0.999,\n",
    "    epsilon = 1e-07)\n",
    "\n",
    "opt_Ftrl = Ftrl(\n",
    "    learning_rate = learning_rate,\n",
    "    learning_rate_power = -0.5,\n",
    "    initial_accumulator_value = 0.1,\n",
    "    l1_regularization_strength = 0.0,\n",
    "    l2_regularization_strength = 0.0,\n",
    "    l2_shrinkage_regularization_strength = 0.0,\n",
    "    beta = 0.0)\n",
    "\n",
    "params_grid = {\n",
    "    \n",
    "    # optimizer [opt_SGD, opt_RMSprop, opt_Adam, opt_Adadelta, opt_Adagrad, opt_Adamax, opt_Nadam, opt_Ftrl]\n",
    "    'model__optimizer': [opt_Adam],\n",
    "    \n",
    "    # Número de camadas\n",
    "    'model__layers': [3, 4],\n",
    "    \n",
    "    # Neuronios por camada\n",
    "    'model__n_dense': [128],\n",
    "    \n",
    "    # activation ['relu', 'sigmoid', 'tanh', 'selu', 'elu']\n",
    "    'model__activationA': ['sigmoid'],\n",
    "    'model__activationB': ['sigmoid'],\n",
    "    \n",
    "    # Ridge regularizer\n",
    "    'model__regL1': [0],\n",
    "    \n",
    "    # Lasso regularizer\n",
    "    'model__regL2': [0],\n",
    "    \n",
    "    # Dropout regularizer\n",
    "    'model__dropout': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search e Cross Validation\n",
    "\n",
    "grid = GridSearchCV(estimator = estimator,\n",
    "                    # negative mean square error\n",
    "                    scoring = make_scorer(score_func = mean_squared_error, greater_is_better = False),\n",
    "                    verbose = verbose,\n",
    "                    return_train_score = False,\n",
    "                    cv = nKFold,\n",
    "                    # n_jobs = -2 # \"-2\": mantem 1 processador livre\n",
    "                    # pre_dispatch = '2*n_jobs',\n",
    "                    refit = True,\n",
    "                    param_grid = params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View grid\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Monitoramento de Otimização\n",
    "\n",
    "# tensorboard --logdir=logs/\n",
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "\n",
    "fit_params = {\n",
    "    'model__batch_size': batch_size,\n",
    "    'model__epochs': epochs,\n",
    "    'model__verbose': verbose,\n",
    "    'model__validation_data': (x_teste, y_teste),\n",
    "    'model__shuffle': True,\n",
    "    'model__validation_steps': None,\n",
    "    'model__validation_freq': 1,\n",
    "}\n",
    "\n",
    "grid_result = grid.fit(x_treino, y_treino, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado do SearchGridCV\n",
    "\n",
    "pd.concat([\n",
    "           pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_fit_time']],\n",
    "           pd.DataFrame(grid.cv_results_['params'])\n",
    "          ],\n",
    "           axis=1,\n",
    "           join='inner').set_index('rank_test_score').sort_values('rank_test_score')\n",
    "\n",
    "# Função score com base no SearchGridCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid.best_params_\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative mean square error - Função score do Modelo Keras encapsulado\n",
    "best_model.score(x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative mean square error - Função score do Modelo Keras encapsulado\n",
    "best_model.score(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'y': y_teste, 'previsao': best_model.predict(x_teste)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(best_model.predict(x_teste), y_teste);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise n - XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento de Dados Para Construção de Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Construção, Treinamento e Avaliação do Modelo 1 com Regressão Linear (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of determination\n",
    "\n",
    "reg.score(x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLoss = ((reg.predict(x_teste) - y_teste)**2).mean()\n",
    "regLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'y': y_teste, 'previsao': reg.predict(x_teste)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.residplot (reg.predict(x_teste), y_teste);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resíduos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Construção, Treinamento e Avaliação do Modelo n com XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
